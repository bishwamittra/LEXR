{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from RNN2DFA.LSTM import LSTMNetwork\n",
    "# from GRU import GRUNetwork\n",
    "from RNN2DFA.RNNClassifier import RNNClassifier\n",
    "from RNN2DFA.Training_Functions import mixed_curriculum_train\n",
    "import Tomita_Grammars \n",
    "from RNN2DFA.Training_Functions import make_test_set,make_train_set_for_target\n",
    "from RNNexplainer import Explainer\n",
    "import pandas as pd\n",
    "import LTL2DFA as ltlf2dfa\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from specific_examples import Alternating_Bit_Protocol\n",
    "abp=Alternating_Bit_Protocol()\n",
    "generator_dfa=abp.dfa\n",
    "target_formula=abp.target_formula\n",
    "alphabet=generator_dfa.alphabet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from specific_examples import Email\n",
    "email=Email()\n",
    "generator_dfa=email # to make everything work\n",
    "target_formula=email.target_formula\n",
    "alphabet=email.alphabet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reber grammar\n",
    "from specific_examples import Reber_Grammar\n",
    "rg=Reber_Grammar()\n",
    "alphabet=rg.alphabet\n",
    "generator_dfa=rg\n",
    "sample_train_set=[]\n",
    "for i in range(100):\n",
    "    seq, _, _ = rg.get_one_example(maxLength=10)\n",
    "    sample_train_set.append(seq)\n",
    "    # print(rg.classify_word(rg.sequenceToWord(seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "made train set of size: 1169 , of which positive examples: 424\n"
    }
   ],
   "source": [
    "# balanced parentheses\n",
    "from specific_examples import Balanced_Parentheses\n",
    "bp=Balanced_Parentheses()\n",
    "bp.get_balanced_parantheses_train_set(10,1,10)\n",
    "alphabet=bp.alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "DFA:->\n - alphabet: ['l', 'r', 'a', 'b', 'c', 'd']\n - Q: [1, 2, 3, 4]\n - q0: 1\n - F: [4]\n - delta: {1: {'000000': 2, '000001': 2, '000010': 2, '000011': 2, '000100': 2, '000101': 2, '000110': 2, '000111': 2, '001000': 2, '001001': 2, '001010': 2, '001011': 2, '001100': 2, '001101': 2, '001110': 2, '001111': 2, '010000': 2, '010001': 2, '010010': 2, '010011': 2, '010100': 2, '010101': 2, '010110': 2, '010111': 2, '011000': 2, '011001': 2, '011010': 2, '011011': 2, '011100': 2, '011101': 2, '011110': 2, '011111': 2, '100000': 3, '100001': 3, '100010': 3, '100011': 3, '100100': 3, '100101': 3, '100110': 3, '100111': 3, '101000': 3, '101001': 3, '101010': 3, '101011': 3, '101100': 3, '101101': 3, '101110': 3, '101111': 3, '110000': 4, '110001': 4, '110010': 4, '110011': 4, '110100': 4, '110101': 4, '110110': 4, '110111': 4, '111000': 4, '111001': 4, '111010': 4, '111011': 4, '111100': 4, '111101': 4, '111110': 4, '111111': 4}, 2: {'000000': 2, '000001': 2, '000010': 2, '000011': 2, '000100': 2, '000101': 2, '000110': 2, '000111': 2, '001000': 2, '001001': 2, '001010': 2, '001011': 2, '001100': 2, '001101': 2, '001110': 2, '001111': 2, '010000': 2, '010001': 2, '010010': 2, '010011': 2, '010100': 2, '010101': 2, '010110': 2, '010111': 2, '011000': 2, '011001': 2, '011010': 2, '011011': 2, '011100': 2, '011101': 2, '011110': 2, '011111': 2, '100000': 3, '100001': 3, '100010': 3, '100011': 3, '100100': 3, '100101': 3, '100110': 3, '100111': 3, '101000': 3, '101001': 3, '101010': 3, '101011': 3, '101100': 3, '101101': 3, '101110': 3, '101111': 3, '110000': 4, '110001': 4, '110010': 4, '110011': 4, '110100': 4, '110101': 4, '110110': 4, '110111': 4, '111000': 4, '111001': 4, '111010': 4, '111011': 4, '111100': 4, '111101': 4, '111110': 4, '111111': 4}, 3: {'000000': 3, '000001': 3, '000010': 3, '000011': 3, '000100': 3, '000101': 3, '000110': 3, '000111': 3, '001000': 3, '001001': 3, '001010': 3, '001011': 3, '001100': 3, '001101': 3, '001110': 3, '001111': 3, '100000': 3, '100001': 3, '100010': 3, '100011': 3, '100100': 3, '100101': 3, '100110': 3, '100111': 3, '101000': 3, '101001': 3, '101010': 3, '101011': 3, '101100': 3, '101101': 3, '101110': 3, '101111': 3, '010000': 4, '010001': 4, '010010': 4, '010011': 4, '010100': 4, '010101': 4, '010110': 4, '010111': 4, '011000': 4, '011001': 4, '011010': 4, '011011': 4, '011100': 4, '011101': 4, '011110': 4, '011111': 4, '110000': 4, '110001': 4, '110010': 4, '110011': 4, '110100': 4, '110101': 4, '110110': 4, '110111': 4, '111000': 4, '111001': 4, '111010': 4, '111011': 4, '111100': 4, '111101': 4, '111110': 4, '111111': 4}, 4: {'000000': 4, '000001': 4, '000010': 4, '000011': 4, '000100': 4, '000101': 4, '000110': 4, '000111': 4, '001000': 4, '001001': 4, '001010': 4, '001011': 4, '001100': 4, '001101': 4, '001110': 4, '001111': 4, '010000': 4, '010001': 4, '010010': 4, '010011': 4, '010100': 4, '010101': 4, '010110': 4, '010111': 4, '011000': 4, '011001': 4, '011010': 4, '011011': 4, '011100': 4, '011101': 4, '011110': 4, '011111': 4, '100000': 4, '100001': 4, '100010': 4, '100011': 4, '100100': 4, '100101': 4, '100110': 4, '100111': 4, '101000': 4, '101001': 4, '101010': 4, '101011': 4, '101100': 4, '101101': 4, '101110': 4, '101111': 4, '110000': 4, '110001': 4, '110010': 4, '110011': 4, '110100': 4, '110101': 4, '110110': 4, '110111': 4, '111000': 4, '111001': 4, '111010': 4, '111011': 4, '111100': 4, '111101': 4, '111110': 4, '111111': 4}}\n - is_singleton_graph: False\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# use a dfa to generate training set\n",
    "target_formula=\"F(l U (~l))\"\n",
    "alphabet=bp.alphabet\n",
    "import LTL2DFA as ltlf2dfa\n",
    "generator_dfa=ltlf2dfa.translate_ltl2dfa(alphabet=[character for character in alphabet],formula=target_formula)\n",
    "print(generator_dfa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "generator_dfa.classify_word(\"lrl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout=open(\"output/log.txt\", \"a\")\n",
    "fout.write(\".........................................................................\\n\")\n",
    "fout.write(\"Target: \"+ target_formula)\n",
    "fout.write(\"\\n\")\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "made train set of size: 10860 , of which positive examples: 5427\n"
    }
   ],
   "source": [
    "# make training set\n",
    "train_set = make_train_set_for_target(generator_dfa.classify_word,alphabet,max_train_samples_per_length=1000,search_size_per_length=3000)\n",
    "# print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "bbcccc': False, 'acbccbbbcccacbbacbba': False, 'bbcbcbaaacbcbcaccaca': False, 'cbcacbacbaccccbaacba': False, 'cbbccbcbccaacaaacaca': False, 'bbbbcbacccaaacaacacc': False, 'ccaacbcbcbacbcacacbb': False, 'cbccbcccbcccacacbacb': False, 'ccbcccbccbcacbacccbb': False, 'accaccbcccbbaaacbaac': False, 'bcaaacbbbaccaaccaaca': False, 'bbcbcbacaacbbcccbacb': False, 'bacacbcaccaaccaaacaa': False, 'accacaaccbcccbacbcba': False, 'cacacbcbbcccccbbbbbc': False, 'aacbbcbcbbacaaaccbbc': False, 'bbbbbccbacccbbcbcccc': False, 'aacbbbbacbcacaacacbb': False, 'cacbcaaccccaaacbbcac': False, 'bbcbacbaccacccaccbcb': False, 'bcacaaaacbcaaacbcbac': False, 'cbcccbcbacaaacaaacbb': False, 'caacbcaacbbbccbccbbc': False, 'bbaaacbbbaacacbbaccc': False, 'cbbacacbbbccbcccbcbc': False, 'accbcaaacbccacccbaca': False, 'cbccbbccaaacbacccbba': False, 'bbcbbcbcaccacbcbbaac': False, 'baacaccacbbbbbaacaca': False, 'bccbcacaccccbcacaaaa': False, 'caaccbaacbcbcbcacaca': False, 'cbaccbbcbbcbccccbccb': False, 'cbbbbcaccaaccbbbbbca': False, 'bbbacccbbbbcbbbaacba': False, 'cbacaaccacaaacbcbbca': False, 'bccbbacccbcaccccaccc': False, 'aacacbccbbacbbbbacca': False, 'acbbaccaccaaccccacba': False, 'bcbccbccbcbaccbcaccc': False, 'cacbbbcccacbbcbaaaca': False, 'aacacaaccbccbccccbbc': False, 'acccbaccaaaaccbaacac': False, 'ccbcaccaccbaacccaccc': False, 'cbcbbaaccaacbbbbccac': False, 'aacaccccacccaacaccba': False, 'aaaaacbacbbbbbaacbac': False, 'baccaaacbcbbcbaccbcb': False, 'caacacbbccacaacbbaca': False, 'bbccbccbccbccaacacba': False, 'bcacacbbbacbbbcbacaa': False, 'aacbccccbcacbbacbbac': False, 'bbacbbaccbaaaacaccbc': False, 'bcbacacbaacacbacacbc': False, 'bcaaaacaaaccbaacbccc': False, 'bcbbcbbbbbccbbcaacca': False, 'accacbbcccbcbaacacac': False, 'ccbbacbccacccaaaacbc': False, 'accacaacbccbaaaccbba': False, 'cbcaacbcaacaacbcccca': False, 'cbcbcacaaacaaacccccb': False, 'acaacbbcbcbccbacbbcb': False, 'acbcbbcccbcacbbacaca': False, 'ccaacbcbacbbaaccaaca': False, 'accbbcbbcacbccbcbbca': False, 'cacaccbccacbccbaccca': False, 'aaacbbcacccbbacbacbb': False, 'bccbaccbaaacbacbbccb': False, 'aacbcbaaacacbbaacccc': False, 'cbaacbbbacaacbbbaaac': False, 'bbbcaccbaaccbbbbbbba': False, 'bcacaccbbccbbbbcbbaa': False, 'ccbcacbaccbacaaaacbc': False, 'bacaaacbcacbbacbacac': False, 'bcbcbcbccbacaacacaca': False, 'bbacbbcbccaacbbbacca': False, 'bacaccbaaacacbcacbca': False, 'bbcbcbbbbcbcbbacccac': False, 'aacaacaccacbacbbbaca': False, 'aacbcccbacaaccbbbacb': False, 'acbaacaaacbbccacbaaa': False, 'cbaccbbbccccacccbbcc': False, 'cbccaaccbbaacbcbccbc': False, 'bcbcbbbbbacaacccaaca': False, 'cbaccbbbccbbccbacccc': False, 'cbacbbbcaacacbbcbacb': False, 'baaaacccbccbcbccacbb': False, 'cacbbccbbbcbacbbacbc': False, 'ccbcacbbaaccccbaacac': False, 'acacbacbbbacbaacbbcc': False, 'accaacaccaaaacccacca': False, 'acacbacccbbacbccacaa': False, 'ccbcacbbcccbaacacbcb': False, 'baaccbbcbccaaccbbcca': False, 'cbbbaccaacbaaaaacccc': False, 'cbccaacbccbccbbcacac': False, 'cbbcbaaccbcaccaaaaaa': False, 'bbbbcbaccccbbcbbcacc': False, 'accbacbccccacaccbbba': False, 'ccbaacaacbbcbbccaccc': False, 'ccaacbcccaaaacccaaac': False, 'bccbbbcacacacbaccbcc': False, 'ccbbacbaaaccccccbbba': False, 'bbccbbbaaacbbacbbcbb': False, 'bcacbbcaacbcbccbbacc': False, 'cbbaacbcbccbaacaccaa': False, 'baaaacbcaccbbbaaacca': False, 'cccacbcbbbbcccbacbcc': False, 'bccacaaacbbcbbccbbcc': False, 'bcacacaccacbcccaccca': False, 'bcaccbcbccbbcaaacbca': False, 'cbacbcbccbccacbcacaa': False, 'bacacbaacbcaacbbbcba': False, 'bcbbccbcccccaaaccacc': False, 'bacbacbbcbbccbbcaaaa': False, 'aaaccbcbbacccccccbcb': False, 'ccbbbbbaaaacaccbaaca': False, 'cbcaaaccccaaaacacaaa': False, 'ccccccacaccccbcbacba': False, 'cccbcacbbcccbcccccba': False, 'cbbaaacbacacbccbaaac': False, 'cbccbaccbbccbccaaacb': False, 'cacbbbbbacbbcbcbbbca': False, 'ccccaaacccbaccccbacb': False, 'cacbcaacbbcbcaacbcca': False, 'aaccacaaaacccccbaaac': False, 'bbbaacbaccbcacbccccb': False, 'acbcbaacbbcbaccbaacc': False, 'acbccbbbcaccacbbbcba': False, 'baaaccbbbbaccaacaaac': False, 'aaccccccbcaccbcaaccc': False, 'cbbaacbacbbbacaccaaa': False, 'bbccbbacbccbcaaacbca': False, 'cacbcbacbbccaaccbbcc': False, 'bbbaacbcbbbcbacccbca': False, 'ccbbaccacbacbcbcbaac': False, 'cccaacbbbccaacbbbbba': False, 'cbcaacacacbcbbcacbaa': False, 'acbbcbbacacbcccacaaa': False, 'bbcbccacccbcaacccbaa': False, 'cbacbbaccaccbbbccccb': False, 'cbbbaccacbacccaaaaaa': False, 'acbccbaacbbaaacbbbba': False, 'baccbcbbbcaaaacacaaa': False, 'cbcacbbccbbbacbacacc': False, 'acacbbaacbaaccccaacb': False, 'bbacaccaaccccbacacbc': False, 'cbbacccccaaaaccccccb': False, 'bbcbaaccccbccbbcacaa': False, 'aacacccaacbbacbbbcac': False, 'caaacbcbcbbcacacbcba': False, 'aaaacbbbcaaacbcaaacb': False, 'bccccaaacccbcacacbbb': False, 'cbbbacbbacacbcaaccca': False, 'cacbaccbcbcacccccaca': False, 'bacbbcbcccbacccbbaac': False, 'bcbcacacbbbbccbbbaca': False, 'baacccacbaacaaacbcba': False, 'bccaaaaacacbaaccbbac': False, 'cccaaccbccaaccccbaaa': False, 'bcacbccbacbcbbacbccc': False, 'bbccccbbaccbbcaccccc': False, 'cbcaccbbbbaacacbcbaa': False, 'aacbcaacbbcbacccccbc': False, 'baaacbcaacaaaaccbbca': False, 'acbccbacccccbbbacbcb': False, 'bbbcbcccaccbaacacaac': False, 'ccccbacbacbacacbbaac': False, 'acbaccbaacbacaccbbaa': False, 'bbacccacbacaaaacacac': False, 'cacbaccbccbacbbbcacb': False, 'bbaccacbbccbaacccccc': False, 'bbaaccbcaaccccccbccb': False, 'bbacbbbcccccccaccbaa': False, 'bbcccaacaacbbcbaacca': False, 'aaacbcbbacacbccbbccc': False, 'accaacccbcbbbcacbaaa': False, 'bcacbbcaaccbaccbcbac': False, 'cbbccaaacaccccbcaaaa': False, 'bbcaacacaacbbaacbaaa': False, 'caacacccccccbacbcbba': False, 'bbcccbaacbcbccbaacaa': False, 'acbcbacacbacbaccaacb': False, 'bacbcbcaacaccbbbbbba': False, 'bcbccacacaacbacccbba': False, 'cbbacccbaaccacacacbc': False, 'acccacbcccaacbcaacbc': False, 'bbccbbacacacbbcbacac': False, 'bbaaaacbbbaaacaacbac': False, 'bacccccbbbaaaccbbbba': False, 'bbcbbbbacaccbcaaccbc': False, 'cacacccbcacbcccaacba': False, 'acccbaaaccaacccaacba': False, 'acacccacacbbcccbbcca': False, 'cacacccacbaccbbbbbba': False, 'bcbaacbbbacbaaacbbcb': False, 'caccbacbbbbbccbbcbcc': False, 'acaaaacbacaaacbacbcb': False, 'bbbacbcbccacacbcbcac': False, 'cbacbbbcaaccbbbbcbba': False, 'cbcbaacbcccbaacbccca': False, 'acbaccbcbbcccbbcacaa': False, 'cccbaccbbacccccacaca': False, 'bccaccbbaccbbcacbcaa': False, 'bbbbccbacbbccbcbcacc': False, 'ccbcbcbccacccbacbcaa': False, 'bcccbaacacccaccacbcc': False, 'ccacbccbaaacaacccbac': False, 'cbaccbbbaacccbcbbbaa': False, 'acbacbaacaacaccbbaca': False, 'cacacccccaaacaaacccc': False, 'ccacccbcccaccccbbaac': False, 'cccbbacaaaaaaaaaacbc': False, 'bbccbbacaacbbbbbbbbc': False, 'acaccacccbacbcbccbca': False, 'ccaccccbbbacaaaacbca': False, 'ccccbbbbbcaacbbacbac': False, 'bacbccabaaaacacacbcbcbbca': True, 'abcbbcbabcabbcbaccacbabab': True, 'cbbaccbaaabbccbbabbbabbbb': True, 'acbacaaabbbbbababcababbca': True, 'baaaaabbbcbcbccbcaaacabac': True, 'ccabcaacabbbaccbabacaabbb': True, 'acbcabccbcacbcabaaaabbccb': True, 'aaabaabbbbacbccccabbccacc': True, 'abaaaacbaccabbbaabaabbbcb': True, 'abbcbbbcbcaccbacaccbacaac': True, 'aacaabcaaccbcabaaaccbcbbc': True, 'cabbbcaaacaabcacccaabbcbb': True, 'ccbbbacbcabbcccaaacaccbab': True, 'abbbccbabbbbbaacaacbbbcaa': True, 'aacacacccbbbbbacaabbacccc': True, 'bbabcaabcbabcbcaccbabaaaa': True, 'caacbabacabcbbaaaacccabcc': True, 'cbcbbaccacbcabbcaaccbaccb': True, 'bbaacbcbaccabbbaacbcbcbbb': True, 'abcbbccacbacbacbbbababaca': True, 'aaaacccbcacbbabccaccaabca': True, 'babcbcbacbbbcbcbbacbaaaab': True, 'caaababbccbcbaaccbaabcaab': True, 'abaaacabccbbaacacccccbccc': True, 'bbbbbcacaccbcaacbacaabcab': True, 'acaaccbbccbbcabcbccbbbacc': True, 'bcbbbbabbaaababacccbacbba': True, 'bbabcacaaabcccaacbcacbcab': True, 'ccabaaabaccabbbbabccbbbab': True, 'acbbbcaabcacabbcabbbcaccc': True, 'ccbbcabbbcbbcabcbbcbacaaa': True, 'cbcbaccbbcaacaacbccbbabab': True, 'cbbbbbcbaababaabbaabccabc': True, 'abacbccccbabcabaaabababac': True, 'cabccababbaacbbabaabaaaca': True, 'aaaabbbbccccbacbacbabcaac': True, 'babcbcacabbbaabababbcaaab': True, 'bbbcccbacabbbcccabcbaccca': True, 'bacbabbbcbcbabccabababccb': True, 'cccbabbbbabbacccaacababbc': True, 'abbacbbccabcabccbbbbabcac': True, 'cbaabbcababacabaaabccaabc': True, 'cccbbbcbaccabaaabaccbccab': True, 'aaaacabacacbccbbbcbbacbba': True, 'cabbcaabcccccacbacbabcaab': True, 'cabacaaababaabccbacbaabcb': True, 'abbaccababbcbbacbcabccacc': True, 'abacaccbabccbcbcbaccacaba': True, 'bcbcbcbcabcabbacaabbbccab': True, 'baababbabccaabbcabbbabbbb': True, 'caacacababbbaaabacbbcaaab': True, 'aabbbaababbabaaaccacbabbc': True, 'baacaccbaabbacbcacbbcbbba': True, 'abcacbaacacccbbcbbbbbabaa': True, 'cbaacacbaabcaaacbaaaaacbc': True, 'bcaaaacabcbcacabbccbaaccb': True, 'cbccbcbcbaabaaabbcacccbcb': True, 'cabacbbbaccbcabacacabccca': True, 'baaabaabbcaaccbbacabbccba': True, 'ccaaccacabccccbcacacbacba': True, 'cacbbacbabbacccaccbcbcaaa': True, 'ccaaabbbabbcccbaaabcabbbb': True, 'cacbaaaaaabacbacaccbaabcb': True, 'cbcabaacaabcacbbabccbaaaa': True, 'aaaacccabaaacabcaaacbbcba': True, 'aaccabcababccbccacccaccaa': True, 'cccaabbbbbacbbaacaaacbbcc': True, 'cbaccbcaaccbcccabbacccbca': True, 'cbcbcaccbabacabacbcbaacaa': True, 'abbaccccbcbcccbccaabbbacb': True, 'bccbcbcaabaaacccaaabcabcc': True, 'cabbcbbcabacbbcabbcababca': True, 'bbcabaaaacbcbabbacbaccbbb': True, 'cccbcaabcababcccaabbaabbb': True, 'bcaacaaacbacccccccbacaabb': True, 'caacbbacabacabbccbaabaaaa': True, 'caaccbbbbbaacaabbbaabcbcb': True, 'bbbaaabcabbbbbacabbcabbca': True, 'ccccccbbbbcbbaababbbbcacc': True, 'acacbcacacccabaccbabccabb': True, 'cbabcbccbbacbaaccaaabacac': True, 'cccbccbcbacabccbabbabaaaa': True, 'cabcacbbbbbcacaabcbccabab': True, 'ccbbcccaccbbbbabacaacccbb': True, 'accacbacbaaabcbbaacbabbac': True, 'aacababcccccababaaaabacbb': True, 'bcaababcccbcabbcbacbaabca': True, 'bbcaabbaccacaabaacacbcacc': True, 'bbccaccbccaabcbcbacaaccbc': True, 'abaccbaaacbaccacaabccabcc': True, 'bacbaccbcaabccccbcacabaab': True, 'cabacbabbcaaccbaabbcaabab': True, 'acaccbbbbacbbbaabccbccacc': True, 'caabccabcaccbaaabaaaabbaa': True, 'bbacbbcaabaabbacabcccaabb': True, 'accbaccacaccbbaaaabcccbca': True, 'ccbcabbcababccbbcaaccaabb': True, 'bcbcbabbcacacaacbabbbbcba': True, 'acacaaccabcabbbbcacbcaaab': True, 'babbcbcaabaacbbcbabccbaac': True, 'ccbbaacccccababbaacbbbcbc': True, 'caababbbccacbaaaacccbcbcb': True, 'cbcaaaabcbbababbaacacccbb': True, 'bbccabcbccacaacbbcaacbccc': True, 'bacbcbaccacbaccbbbcabbbcc': True, 'babbacbaaaaaccaabccbcaaab': True, 'bbaaccbbbbcabccbcabbbcacc': True, 'abbbaabbacbcbacacabccbcab': True, 'aacbacccabaccbbaaacbbbbba': True, 'bcaaacbabcccbcbbacbccbccb': True, 'ccbaccccccaaabccaacaaabab': True, 'cabcaaacacbabcbbabaaccccc': True, 'cccbcaaabcaccbabccbaabccc': True, 'abbcccbabacbccacbaccaaaca': True, 'aaabcbabccacacabccabbbbcc': True, 'cabbcbccaccacaaaabcaacaaa': True, 'acaaaacbacbaaccbbcabcaaba': True, 'bcbbcaaaccbbcccabccababac': True, 'babacbaccacabcabcacbbaaca': True, 'bcaccacacaaacabcacabcaaaa': True, 'bbaccbbabaabacbcbaabbcacb': True, 'cbcccbcbaaccaaacccabacccc': True, 'bcbbbbccbcbcacccbabcaabba': True, 'acacccacaabcacbaabbaababc': True, 'bbabbcbbbccaaabaabaabaaba': True, 'cbcccaabcacbaacbcbabcccab': True, 'cccbbcbcbbbcbbccccbacbcbb': False, 'bbbcbcccccbaacccaacbcacca': False, 'bbbbbacacbcccccacaacbccbb': False, 'bcaccbbaaacbcacbcaaacacba': False, 'ccacbaaacbbcbcacbbcbcbbca': False, 'bbcaaaaacacacaacbaaacccbb': False, 'accbaccbbaaaccbaacbcbcbba': False, 'bccbbcbcbcacacaaaaaacccaa': False, 'cbaaaccaaccaaaaccaccccaaa': False, 'acbcbcccbaccbbbbbbaacbbac': False, 'bcbaccccbbaccbacaaacccccc': False, 'bbbaaaaccbccbbcbbcccbcacb': False, 'aacbccacccccbacccacaaccba': False, 'bccbcbbbbbaccaccbbbccbcac': False, 'bbbcbccbaacccacaaacccaacc': False, 'bacbbbbacbbcaaacaccccccca': False, 'cacbcaacaaccbbcbbbbccccba': False, 'baaccbcbacbbcaacacbacbbcb': False, 'bbacbbbcbaacbbbbbbaacbbbb': False, 'cacbcbcbacbccbccbcaccbbcb': False, 'cacccacaaacaacaccbcbacbaa': False, 'caaacacbacacbacacbbcaaacc': False, 'acccbbbbccbacbbbbbcbcaccb': False, 'cbbbcbccbbbccccaacccccbac': False, 'bcbbcaacbcbbacaaccacbccca': False, 'bbcaccacbcbcbbacbcbccaccc': False, 'cccaaccbacccacccccbaccbcc': False, 'cccbcbbbbaacaccccccacbbca': False, 'acbaacaaaaccbbbaccbcbcaca': False, 'bcacccaccccacbccbcaacbccc': False, 'acbbcaacbacaccaaccbcbacbb': False, 'acbccbacbacaaacbbccbcaaca': False, 'ccaaccbccccbbaaaaaccbccbb': False, 'bacccaacacaacacbbbacccaaa': False, 'acaccacbcaacbccaacbaccaca': False, 'bacbbacbaacacacccbcaccbbb': False, 'ccbbbccbcbbcaaaccbccbbbbb': False, 'ccbcaacccccccaacbacbcccbc': False, 'bbcbbccbacaacacaccaccbcba': False, 'cbacacbbaccbcacaccbbcbaac': False, 'bcbccbccccaacbbcaccbcacba': False, 'bbccbbcbacaacbbcaacaccaca': False, 'ccaaacccccccbcbbbccacacac': False, 'aacbcccccbcaacacaaccbbbaa': False, 'accbbbccbacbaaaaaaaccbbba': False, 'cccaaccaccbaccaccaacbacbc': False, 'bcaacccbcccaacbbcbbaccbaa': False, 'aacbbcaccacbcccacbcbccbaa': False, 'bbccaaaacbbacccacbcbbbcbb': False, 'baccbbaaaacccacbbccbcbbba': False, 'aaaacccbccacbaacaccbbbcca': False, 'aaaaaaaaccbcbaaacaacbbaca': False, 'bbbcbccbbaaacbaacbaacbcbc': False, 'bbbbbacaccbbacbcaacbbbaca': False, 'cbccccbbbbacbcacacbbccacb': False, 'aaaccbcbcaaaccaaaacacacbb': False, 'cacbccbcbacbcaaccbcacacbb': False, 'caccbcbaaaaacbcccbbbbbbbb': False, 'bbaccbaccacaaacbcbaaccbaa': False, 'acbaacbaacbcbbbacbacbbbcc': False, 'bacbcbcaaacccbcbcbbbccbca': False, 'bbacbccbbccccacaaaaaccaac': False, 'cbcbaaaccaacbcacbbbbaccba': False, 'cbaaaacaccacacaccbbccacac': False, 'cccaccccacacaccbcbcbaaccc': False, 'aaacbbcbbbbbbaccaccacaacb': False, 'accbcbcbacbacaccbcbaacccc': False, 'ccbacacbbcccccccbbbcacaaa': False, 'bccacaccccbcbcaacacbbbaac': False, 'cacaccacbbcaacbcccbcaacbc': False, 'bcbbcccbbbbbcacccaacbcccb': False, 'ccccbcacbaaacacaaaaacccba': False, 'aacccbacaacacbbacbaaccbca': False, 'acccccbcbcbbacccbcaacbbcb': False, 'bacacbacccbbacacbbcaccaac': False, 'cbbcccbacbcaccbaaacbaacbc': False, 'bbbbacbccbbcbcccbbbacaacc': False, 'acbcccbacacccbbbaaccccccb': False, 'cbcbbbcbcbccccbcaaccccacb': False, 'caaaccbcccbbcbbbbcbaaacbc': False, 'bbcbcaaccbbbcbccbaaaccbcb': False, 'cacaaaccbbccacaccccbbaccc': False, 'accbaacbaaccaaacacbbbaaac': False, 'caacbaacaccbcccbaacacaaca': False, 'bccaaacbacbcbbbaccaccaccc': False, 'cacccaacbaccaccbbaacacbcc': False, 'bbbbacbbbbcbcaacccaccacaa': False, 'baaaaaccccbbcbcacccaaacba': False, 'bacbbaacbbbacbbbbbccbbcba': False, 'bacaccaccbbbccaccbcbccbca': False, 'ccbcbcbacbcacacccbcbbacac': False, 'bccbbcacccbccbaaacbccbcbc': False, 'bbcbacacbacaccbbaccbbcbaa': False, 'bbbbcbbbccaccbbaccbcccaaa': False, 'accacbbbaacbaacaaacaccbba': False, 'caccacccaccaacaacaccbbaca': False, 'bbcbbcbbbcbacaccbccacbccc': False, 'cbbcbccbacbcacaaacaccbaaa': False, 'cbcbbccaacacaaaacbcacccbb': False, 'bbcbacbccccbbbbacbcbbbbba': False, 'accbcccbaacbcbbbcbcaaacca': False, 'bbbcbbccbbbbcbacaacaaacba': False, 'aacbbbcaacaacacbacacbaacb': False, 'cbbcaaccaccccbaaacaaaacba': False, 'caaacacbcbcbcbaccbbbbcbac': False, 'caaccaaccacbccbbacacaaaaa': False, 'bcabccaaacbbcbaabbcaaaacabaacc': True, 'baccbaaabbaabaacbcbbcbbacbbbbb': True, 'bbcaccccaccaccabaaaacabbcaccac': True, 'cbcabacacbbabcacacaabcaabacbbb': True, 'caacbacbcacacaaaccbcabbcbcbabb': True, 'bbacaababccaccabbbbbbaacbcaacc': True, 'bcbcabcccaabababbbaabbaacacbab': True, 'aabbacaacccccaabcbabaaabbcbaab': True, 'bbacabbaababcaacabbaaababccaab': True, 'bbbbbabbbacccbaabcbbaabcbbcbbb': True, 'acaabccbbcbcbaabcaacbbcabcaacc': True, 'cbbcaaabcccccbbbcbabacaabbbcbc': True, 'aaababcabbccccccbcabcbbbbccbab': True, 'bbacacabaaabcbabbaaabccbbacaca': True, 'bbcbccaccabcbccbcbaabbbccccacc': True, 'ccbbcaabaaabbcbbccacbccabbcaca': True, 'bbcacacbbcabbabbbbbacbbbaabbbb': True, 'bcbcbaccbbccabbccbccacbabacbaa': True, 'cacccbaaabbaacacabccbbcccccbba': True, 'bbbcbacacacbacaaccbbabcbcbbaba': True, 'aabbbcbccaabbccaaabcbbcbbcbaac': True, 'ccbbabcbbccbbcbcaaabcbabcbbccc': True, 'abbbbcaaabccababbbbacaacabcacb': True, 'bcabaaacacbcbabacbbabcaacbbccc': True, 'bbacbacacbcaabbbbbbacaaaaaccba': True, 'abbcbaccaaacabbbabacaacabaabac': True, 'abacabacbbbcacabbbababbcacbabc': True, 'caaacbbbcacacaaababaacbacccbbb': True, 'bccbcbacaacabaccabcacacaccabbc': True, 'aabbbaaabbcbaaacbbaabccbbbcbbb': True, 'cbbcacbbcabbbbbcacbbbcbcaaabcc': True, 'accabbcacababaabccbcccabbaaaac': True, 'caabbcbaaaaccbbacaaacacaacaabc': True, 'cbaacbabacccbabcbccbcbabbacbaa': True, 'bcbcabbbbaccccccbccccbccaccbac': True, 'acabbcbcccbacbbccabccbaacaabac': True, 'babbbabbcaacbccbbbbabaccaccbab': True, 'aacbcacbbaacbccbabacbabbcbaaca': True, 'accaabbbacccbabbcabbccaaccccbc': True, 'aaacbccbccaacaaabbccaccabcabbc': True, 'baabcccbbacacccaabbbbbcabccacb': True, 'bbbcbcbcaaccacabbccccbcbbbbcaa': True, 'bcabcacbacbbabacaaabcbabbacaaa': True, 'cccbcbacbaabbabcacbacabbccbcca': True, 'bccacbbacacbccaccbaabbcaccbacb': True, 'ababcbbbabcbcacabccbcbaccbbcba': True, 'bcaaababcbcbccaccbbbaccacababb': True, 'cccbaabaacbacaacbbaabacbbaaccb': True, 'caacbbaaabcaccbaccbcacbbbbcbaa': True, 'acbbaccccbbbcabccabbbccabbbcca': True, 'cbbbbacccccbbbbaaacccccaabacbc': True, 'cbbaabbabcbbcbcabbcabcbaabbcca': True, 'babaabcbcbbcbbbbccbbcbcccccacb': True, 'cabccbabbbbcbcababcbabcbabcccb': True, 'aabaacbccccaabbbccabbabababaab': True, 'bcbaaaccbbabcbcaacaabbbcbbbbcb': True, 'bacabccaababbbcacccbbaabcabcaa': True, 'aacbacabcbbcccacbaabaabaaabaaa': True, 'bbbbcaaabbcbbcaaccbacbababcccb': True, 'cacabcaaabcabccbaccbcbbccbaaca': True, 'bbbbbacbabbccbbacbacabbcbcbcab': True, 'bcbbcbaacbaabbbacabbbccabbacbc': True, 'bbccabaaccbbbccacccccbbccabbac': True, 'ccabbaaaaaaabbaaacacbcaabababc': True, 'baabacbbcacbcacacababbbaccbabc': True, 'bacccbbaaccabcaabcbbabaabbabaa': True, 'acbcacbabaccbbcabaaaacaaacaabb': True, 'cbbabbaabbcbababaabbaacbccbbca': True, 'aaccaabaabacabcbacbbaacabbcbcb': True, 'abbbbcabaccaccbacbbbbcaccaabab': True, 'bbbccccbccbbabbbbbbbbcaabaccca': True, 'aacaaaaaacbcaaacbbcabbcbacccab': True, 'ccbccbcbbaccbbcabbbbabbacacacc': True, 'accbcbbbcbaccbcaccaaacccaaacaa': False, 'acbbaacbccbaccaccacbccbaacbbac': False, 'baaccaccbbcccacbbccaaccbccacac': False, 'acacbaccacbbacbcacccbbbcccbacc': False, 'accacbbaaaaaaccbaaccbbbbcbaccc': False, 'cccbaccaacbacaacccaacccbaacbbb': False, 'cbbacbaccbaccbaacbbbacbbbaaaca': False, 'acbaacbbbaccccbcccccccaaaccbac': False, 'bcaacbacccbccacacaacbcbacbaacc': False, 'ccacbcbaacacacbcacbbcbbcbccacb': False, 'cbcaaaaccbcaccbaccbbbbbbbaccca': False, 'cbbccbccbccbbccaaaccccbcbbccaa': False, 'aaaacacbbacccbbbccacbbccbbcbaa': False, 'bccaaccaccccacaacccacccbcccaaa': False, 'bbbbacbccbbcaccccacbbccbcaaaaa': False, 'aaacaacbacbcacbaaccbbbccacacba': False, 'bcbaccbbcacaccbbaaaacccbacaccb': False, 'bbaaccbaaccacbbbcaaccbcccaccba': False, 'cbbbacaaaaaacacccaccacccacacbc': False, 'ccaccccbacccccbcccbcbbbbacbaca': False, 'bbcbcaaccacacbccbacacacaccccac': False, 'accbbbbccbcbcbbccaaccacacccbca': False, 'bacbbccaacbacbbccacacbbcccbaaa': False, 'cccbacbbcccaaccbccbbbbacaaaacc': False, 'bbcaaccccaacacbacbbacacccbbacc': False, 'bbacbcbcbbccbccacaccaccbccaacc': False, 'ccacacccbbbbbacbcbbbbbcbcbbacb': False, 'aacbbbbbacaccbcbcaacacaaacbaca': False, 'bcbbcbbbccbaaccbbaaaaaaccbbaaa': False, 'cbaaaacccbcbbbacbacaccbbacccbc': False, 'cbbbbcacbbcacbacbaaacbbbaccaca': False, 'bbbacbccbacbbbcacbcbccacccbcbb': False, 'bccacacccbcbcbcccbccbbbbccbacc': False, 'bcbcacbbacbacaaaaacccbbbccbccb': False, 'bbcbbaacbaccccbbbcacaccaaaccbc': False, 'bcccbacbacaacbbcaaacbbbcbbaaac': False, 'cbaccbbaaaaccbacbcccbcbaccbbca': False, 'bbbcbbbcaaaaccbaccacccacacccac': False, 'ccccbaccccbcbccaacbbbbbbcccccc': False, 'bcbacccbbbaaaaaaacbbccbacbcacc': False, 'ccbaacaaaacccbcacbbacbbcbaccca': False, 'ccccbbccbaccbccbbbcbacbcccbcac': False, 'bcccbbaaacbbbaaaccaccacbccaacb': False, 'bacbacacacbcbbaccbcacbbacbcbca': False, 'baacbaacccbacccbccbcbaacbbbaaa': False, 'aaaccbcaacccaaccbbbccbcbbbcbbc': False, 'cacccbbccbcacbbbacbccbbacbbcaa': False, 'cbcaccaacbbbcaaccbacaaccbaacca': False, 'baccbcccbaacbaaccbaccccccbccbc': False, 'caccacacbbaacbbaccbcacacbccbaa': False, 'bbacbbbcbaccaccbbbcbbcccbcaacc': False, 'cbbacbbbbacccacaccbccbbccaacbb': False, 'aaaaaccbbbbbacaacbbcacbccbaccb': False}\n"
    }
   ],
   "source": [
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10860\n10860\n"
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "if(target_formula==\"email match\"):\n",
    "    matching_strings=email.generate_matching_strings(1000,20)\n",
    "    for string in matching_strings:\n",
    "        train_set[string]=True\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "classification loss on last batch was: 0.00046116977508358254\ntesting on train set, i.e. test set is train set\ntest set size: 10860\nrnn score against target on test set:                              10860 (100.0)\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# define rnn\n",
    "rnn = RNNClassifier(alphabet,num_layers=1,hidden_dim=10,RNNClass = LSTMNetwork)\n",
    "\n",
    "\n",
    "# train the model\n",
    "mixed_curriculum_train(rnn,train_set,stop_threshold = 0.0005)\n",
    "rnn.renew()  \n",
    "dfa_from_rnn=rnn \n",
    "# statistics\n",
    "\n",
    "def percent(num,digits=2):\n",
    "    tens = pow(10,digits)\n",
    "    return int(100*num*tens)/tens\n",
    "\n",
    "print(\"testing on train set, i.e. test set is train set\")\n",
    "# we're printing stats on the train set for now, but you can define other test sets by using\n",
    "# make_train_set_for_target\n",
    "\n",
    "n = len(train_set)\n",
    "print(\"test set size:\", n)\n",
    "pos = 0\n",
    "rnn_target = 0\n",
    "for w in train_set:\n",
    "    if generator_dfa.classify_word(w):\n",
    "        pos+=1\n",
    "\n",
    "    if dfa_from_rnn.classify_word(w)==generator_dfa.classify_word(w):\n",
    "        rnn_target+=1\n",
    "print(\"rnn score against target on test set:                             \",rnn_target,\"(\"+str(percent(rnn_target/n))+\")\")\n",
    "\n",
    "# dfa_from_rnn=generator_dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\npositive traces---> \n[]\n\n\nnegative traces---> \n[]\n\n\n\nlearned LTL formula: true\nLearning took:  0.04761385917663574  s\nEQ test took  0.0027091503143310547  s\nnew counterexample:   should be rejected by implementation\n\n\npositive traces---> \n[]\n\n\nnegative traces---> \n['']\n\n\n\n0  iteration complete\n\n\n\nlearned LTL formula: false\nLearning took:  0.06301116943359375  s\nEQ test took  0.039186954498291016  s\nnew counterexample: ab  should be accepted by implementation\n\n\npositive traces---> \n['ab']\n\n\nnegative traces---> \n['']\n\n\n\n1  iteration complete\n\n\n\nstart formula depth: 1\nlearned LTL formula: a\nLearning took:  0.0792539119720459  s\nEQ test took  0.007261991500854492  s\nnew counterexample: a  should be rejected by implementation\n\n\npositive traces---> \n['ab']\n\n\nnegative traces---> \n['', 'a']\n\n\n\n2  iteration complete\n\n\n\nstart formula depth: 1\nlearned LTL formula: (X b)\nLearning took:  0.12215614318847656  s\nEQ test took  0.01376795768737793  s\nnew counterexample: bab  should be accepted by implementation\n\n\npositive traces---> \n['ab', 'bab']\n\n\nnegative traces---> \n['', 'a']\n\n\n\n3  iteration complete\n\n\n\nstart formula depth: 2\nlearned LTL formula: (F b)\nLearning took:  0.11771607398986816  s\nEQ test took  0.043792009353637695  s\nnew counterexample: b  should be rejected by implementation\n\n\npositive traces---> \n['ab', 'bab']\n\n\nnegative traces---> \n['', 'a', 'b']\n\n\n\n4  iteration complete\n\n\n\nstart formula depth: 2\nlearned LTL formula: (F (X b))\nLearning took:  0.2384319305419922  s\nNo positive counterexample found\nEQ test took  0.08116412162780762  s\nnew counterexample: bb  should be rejected by implementation\n\n\npositive traces---> \n['ab', 'bab']\n\n\nnegative traces---> \n['', 'a', 'b', 'bb']\n\n\n\n5  iteration complete\n\n\n\nstart formula depth: 3\nlearned LTL formula: ((F a) & (X ((F a) -> a)))\nLearning took:  0.9930062294006348  s\nEQ test took  0.020422935485839844  s\nnew counterexample: aba  should be accepted by implementation\n\n\npositive traces---> \n['ab', 'bab', 'aba']\n\n\nnegative traces---> \n['', 'a', 'b', 'bb']\n\n\n\n6  iteration complete\n\n\n\nstart formula depth: 5\nlearned LTL formula: (((F a) U b) & (F a))\nLearning took:  0.730618953704834  s\nEQ test took  0.07998800277709961  s\nnew counterexample: ba  should be rejected by implementation\n\n\npositive traces---> \n['ab', 'bab', 'aba']\n\n\nnegative traces---> \n['', 'a', 'b', 'bb', 'ba']\n\n\n\n7  iteration complete\n\n\n\nstart formula depth: 5\nlearned LTL formula: (((X b) -> b) -> (X (X b)))\nLearning took:  0.853193998336792  s\nEQ test took  0.02760601043701172  s\nnew counterexample: bcab  should be accepted by implementation\n\n\npositive traces---> \n['ab', 'bab', 'aba', 'bcab']\n\n\nnegative traces---> \n['', 'a', 'b', 'bb', 'ba']\n\n\n\n8  iteration complete\n\n\n\nstart formula depth: 5\nlearned LTL formula: ((F (~ a)) U ((F (~ a)) & a))\nLearning took:  1.177685022354126  s\nEQ test took  0.10154604911804199  s\nnew counterexample: ac  should be rejected by implementation\n\n\npositive traces---> \n['ab', 'bab', 'aba', 'bcab']\n\n\nnegative traces---> \n['', 'a', 'b', 'bb', 'ba', 'ac']\n\n\n\n9  iteration complete\n\n\n\nstart formula depth: 5\nlearned LTL formula: (b U ((F b) & (~ b)))\nLearning took:  1.263706922531128  s\nNo positive counterexample found\nEQ test took  0.10284996032714844  s\nnew counterexample: cb  should be rejected by implementation\n\n\npositive traces---> \n['ab', 'bab', 'aba', 'bcab']\n\n\nnegative traces---> \n['', 'a', 'b', 'bb', 'ba', 'ac', 'cb']\n\n\n\n10  iteration complete\n\n\n\nstart formula depth: 5\nlearned LTL formula: ((F b) U (a & (F b)))\nLearning took:  1.260530948638916  s\nNo positive counterexample found\nEQ test took  0.14943385124206543  s\nnew counterexample: acb  should be rejected by implementation\n\n\npositive traces---> \n['ab', 'bab', 'aba', 'bcab']\n\n\nnegative traces---> \n['', 'a', 'b', 'bb', 'ba', 'ac', 'cb', 'acb']\n\n\n\n11  iteration complete\n\n\n\nstart formula depth: 5\nlearned LTL formula: (F (a & (X b)))\nLearning took:  1.5955228805541992  s\nEQ test took  0.2047109603881836  s\n\n\nepsilon= 0.05 delta= 0.05 max_trace_length= 20\nquery: true\nfinal ltl:  (F (a & (X b)))\n\nTime taken: 9.446722984313965\nextracted LTL score against rnn on test set:                       10860 (100.0)\nextracted LTL score against target on rnn's test set:              10860 (100.0)\nextracted LTL score against rnn on test set (with query):          10860 (100.0)\nextracted LTL score against target on rnn's test set (with query): 10860 (100.0)\n      target query      explanation status  rnn score  explanation score  explanation score on ground truth  extraction time\n F(a & X(b))  true  (F (a & (X b)))   True      100.0              100.0                              100.0         9.446723\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# use a query LTL formula\n",
    "query_formula=\"true\"\n",
    "query_dfa=ltlf2dfa.translate_ltl2dfa(alphabet=[character for character in alphabet],formula=query_formula)\n",
    "\n",
    "\"\"\"  \n",
    "Create initial samples\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from RNNexplainer import Traces\n",
    "traces=Traces(rnn, alphabet)\n",
    "traces.label_from_network([])\n",
    "traces.write_in_file()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from PACTeacher.pac_teacher import PACTeacher as Teacher \n",
    "explainer=Explainer(alphabet=[character for character in alphabet])\n",
    "teacher = Teacher(dfa_from_rnn,epsilon=.05, delta=.05, max_trace_length=20, max_formula_depth=10, query_dfa=query_dfa)\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "start_time=time.time()\n",
    "from multiprocessing import Process, Queue\n",
    "explainer, flag= teacher.teach(explainer, traces, timeout = 15)\n",
    "end_time=time.time()\n",
    "\n",
    "\n",
    "print(\"\\n\\nepsilon=\", teacher.epsilon, \"delta=\", teacher.delta, \"max_trace_length=\", teacher.max_trace_length)\n",
    "print(\"query:\", query_formula)\n",
    "print(\"final ltl: \", explainer.ltl)\n",
    "\n",
    "fout=open(\"output/log.txt\", \"a\")\n",
    "fout.write(\"\\n\\nquery: \"+query_formula)\n",
    "fout.write(\"\\nfinal LTL: \"+ explainer.ltl)\n",
    "if(not flag):\n",
    "    fout.write(\" [incomplete]\")\n",
    "    print(\"incomplete formula\")\n",
    "fout.write(\"\\n\\n\")\n",
    "\n",
    "print(\"\\nTime taken:\", end_time-start_time)\n",
    "fout.close()\n",
    "\n",
    "\n",
    "fout=open(\"output/log.txt\", \"a\")\n",
    "# fout.write(\"rnn score against target on test set:                             \"+str(rnn_target)+\"(\"+str(percent(rnn_target/n))+\")\")\n",
    "# fout.write(\"\\n\")\n",
    "\n",
    "performance_ltl_wo_query = performance_ltl_with_target_wo_query = performance_ltl = performance_ltl_with_target = 0\n",
    "\n",
    "\n",
    "for w in train_set:\n",
    "    if dfa_from_rnn.classify_word(w)==explainer.dfa.classify_word(w):\n",
    "        performance_ltl_wo_query+=1\n",
    "    if explainer.dfa.classify_word(w)==generator_dfa.classify_word(w):\n",
    "        performance_ltl_with_target_wo_query +=1\n",
    "    if (dfa_from_rnn.classify_word(w)and query_dfa.classify_word(w)) ==explainer.dfa.classify_word(w):\n",
    "        performance_ltl+=1\n",
    "    if explainer.dfa.classify_word(w)== (generator_dfa.classify_word(w) and query_dfa.classify_word(w)):\n",
    "        performance_ltl_with_target +=1\n",
    "\n",
    "print(\"extracted LTL score against rnn on test set:                      \",performance_ltl_wo_query,\"(\"+str(percent(performance_ltl_wo_query/n))+\")\")\n",
    "\n",
    "print(\"extracted LTL score against target on rnn's test set:             \",performance_ltl_with_target_wo_query,\"(\"+str(percent(performance_ltl_with_target_wo_query/n))+\")\")\n",
    "\n",
    "print(\"extracted LTL score against rnn on test set (with query):         \",performance_ltl,\"(\"+str(percent(performance_ltl/n))+\")\")\n",
    "\n",
    "print(\"extracted LTL score against target on rnn's test set (with query):\",performance_ltl_with_target,\"(\"+str(percent(performance_ltl_with_target/n))+\")\")\n",
    "\n",
    "fout.close()\n",
    "\n",
    "\n",
    "# report in a pandas file\n",
    "result = pd.DataFrame(columns=['target', \n",
    "                                'query', \n",
    "                                'explanation', \n",
    "                                'status', \n",
    "                                'rnn score', \n",
    "                                'explanation score', \n",
    "                                'explanation score on ground truth',\n",
    "                                'extraction time'\n",
    "                                ])\n",
    "\n",
    "result = result.append(\n",
    "    {\n",
    "        'target':target_formula,\n",
    "        'query':query_formula,\n",
    "        'explanation':explainer.ltl,\n",
    "        'status':flag,\n",
    "        'rnn score':percent(rnn_target/n),\n",
    "        'explanation score':percent(performance_ltl/n),\n",
    "        'explanation score on ground truth':percent(performance_ltl_with_target/n),\n",
    "        'extraction time': end_time-start_time\n",
    "    }, ignore_index=True\n",
    ")\n",
    "print(result.to_string(index=False))\n",
    "result.to_csv('output/result.csv', header=False, index=False, mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read result\n",
    "# df=pd.read_csv(\"output/result.csv\",header=None)\n",
    "# df.columns=['target', \n",
    "#             'query', \n",
    "#             'explanation', \n",
    "#             'status', \n",
    "#             'rnn score', \n",
    "#             'explanation score', \n",
    "#             'explanation score on ground truth',\n",
    "#             'extraction time'\n",
    "#             ]\n",
    "# print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}