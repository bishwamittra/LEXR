{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from RNN2DFA.LSTM import LSTMNetwork\n",
    "# from GRU import GRUNetwork\n",
    "from RNN2DFA.RNNClassifier import RNNClassifier\n",
    "from RNN2DFA.Training_Functions import mixed_curriculum_train\n",
    "import Tomita_Grammars \n",
    "from RNN2DFA.Training_Functions import make_test_set,make_train_set_for_target\n",
    "from RNNexplainer import Explainer\n",
    "import pandas as pd\n",
    "import LTL2DFA as ltlf2dfa\n",
    "from RNN2DFA.Extraction import extract\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reber grammar\n",
    "from specific_examples import Reber_Grammar\n",
    "rg=Reber_Grammar()\n",
    "alphabet=rg.alphabet\n",
    "generator_dfa=rg\n",
    "sample_train_set=[]\n",
    "for i in range(100):\n",
    "    seq, _, _ = rg.get_one_example(maxLength=10)\n",
    "    sample_train_set.append(seq)\n",
    "    # print(rg.classify_word(rg.sequenceToWord(seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import specific_examples\n",
    "generator_dfa=specific_examples.Example1()\n",
    "target_formula = generator_dfa.target_formula\n",
    "alphabet = generator_dfa.alphabet\n",
    "query_formulas = generator_dfa.query_formulas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "made train set of size: 1239 , of which positive examples: 145\nout of  1239  sequences 145  are positive. (percent:  0.11702986279257466 )\nexamples per length: [0, 3, 9, 27, 52, 82, 60, 54, 52, 38, 32, 30, 28, 28, 20, 22, 20, 22, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]\nsize of train set: 991\nsize of test set: 248\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def dict2lists(dictionary):\n",
    "    X,y=[],[]\n",
    "    for key in dictionary:\n",
    "        X.append(key)\n",
    "        y.append(dictionary[key])\n",
    "    return X,y\n",
    "\n",
    "def lists2dict(x,y):\n",
    "    # both x and y should have same length\n",
    "    assert len(x)==len(y), \"Error dimension\"\n",
    "    d={}\n",
    "    n=len(x)\n",
    "    for idx in range(n):\n",
    "        d[x[idx]]=y[idx]\n",
    "    return d\n",
    "\n",
    "# for each example, specify a different generating function\n",
    "\n",
    "\n",
    "if(target_formula == \"balanced parentheses\"):\n",
    "    train_set = generator_dfa.get_balanced_parantheses_train_set(100, 2, 50,max_train_samples_per_length=300,                                                         search_size_per_length=20,lengths=[i+1 for i in range(50)])\n",
    "    \n",
    "\n",
    "elif(target_formula == \"email match\"):\n",
    "    train_set = make_train_set_for_target(generator_dfa.classify_word, alphabet,lengths=[i+1 for i in range(50)],\n",
    "                                          max_train_samples_per_length=1000,\n",
    "                                          search_size_per_length=3000, deviation = 20)\n",
    "\n",
    "    # generate more examples that match the regular expression\n",
    "    matching_strings = generator_dfa.generate_matching_strings(\n",
    "        n=1080, max_length=50)\n",
    "    for string in matching_strings:\n",
    "        train_set[string] = True\n",
    "    \n",
    "    \n",
    "\n",
    "elif(target_formula == \"alternating bit protocol\"):\n",
    "    train_set = make_train_set_for_target(generator_dfa.classify_word, alphabet,lengths=[i+1 for i in range(50)],\n",
    "                                          max_train_samples_per_length=100,\n",
    "                                          search_size_per_length=30, deviation = 25)\n",
    "\n",
    "    # generate more examples that match the regular expression\n",
    "    matching_strings = generator_dfa.generate_matching_strings(\n",
    "        n=1050, max_sequence_length=50)\n",
    "    for string in matching_strings:\n",
    "        train_set[string] = True\n",
    "\n",
    "else:\n",
    "    train_set = make_train_set_for_target(generator_dfa.classify_word, alphabet,lengths=[i+1 for i in range(50)],\n",
    "                                          max_train_samples_per_length=100,\n",
    "                                          search_size_per_length=300, deviation = 20)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# print ratio\n",
    "cnt = 0\n",
    "examples_per_length=[0 for i in range(51)]\n",
    "for key in train_set:\n",
    "    if(train_set[key]):\n",
    "        cnt += 1\n",
    "    examples_per_length[len(key)] += 1\n",
    "\n",
    "total_samples = len(train_set) \n",
    "print(\"out of \", total_samples, \" sequences\", cnt , \" are positive. (percent: \", float(cnt/total_samples), \")\")\n",
    "print(\"examples per length:\", examples_per_length)\n",
    "    \n",
    "# split train:test\n",
    "X, y = dict2lists(train_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "train_set = lists2dict(X_train, y_train)\n",
    "test_set = lists2dict(X_test, y_test)\n",
    "print(\"size of train set:\", len(train_set))\n",
    "print(\"size of test set:\", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "G(~a)\nThe dy.parameter(...) call is now DEPRECATED.\n        There is no longer need to explicitly add parameters to the computation graph.\n        Any used parameter will be added automatically.\ncurrent average loss is:  0.005363256785764612\ncurrent average loss is:  0.0008444724996172061\nclassification loss on last batch was: 0.0004894845409329387\ntesting on train set, i.e. test set is train set\ntest set size: 248\nrnn score against target on test set:                              248 (100.0)\n"
    }
   ],
   "source": [
    "fout=open(\"output/log.txt\", \"a\")\n",
    "fout.write(\".........................................................................\\n\")\n",
    "fout.write(\"Target: \"+ target_formula)\n",
    "print(target_formula)\n",
    "fout.write(\"\\n\")\n",
    "fout.close()\n",
    "\n",
    "\n",
    "# define rnn\n",
    "rnn = RNNClassifier(alphabet,num_layers=1,hidden_dim=10,RNNClass = LSTMNetwork)\n",
    "\n",
    "\n",
    "# train the model\n",
    "mixed_curriculum_train(rnn,train_set,stop_threshold = 0.0005)\n",
    "rnn.renew()  \n",
    "dfa_from_rnn=rnn \n",
    "# statistics\n",
    "\n",
    "def percent(num,digits=2):\n",
    "    tens = pow(10,digits)\n",
    "    return int(100*num*tens)/tens\n",
    "\n",
    "print(\"testing on train set, i.e. test set is train set\")\n",
    "# we're printing stats on the train set for now, but you can define other test sets by using\n",
    "# make_train_set_for_target\n",
    "\n",
    "n = len(test_set)\n",
    "print(\"test set size:\", n)\n",
    "pos = 0\n",
    "rnn_target = 0\n",
    "for w in test_set:\n",
    "    if generator_dfa.classify_word(w):\n",
    "        pos+=1\n",
    "\n",
    "    if dfa_from_rnn.classify_word(w)==generator_dfa.classify_word(w):\n",
    "        rnn_target+=1\n",
    "print(\"rnn score against target on test set:                             \",rnn_target,\"(\"+str(percent(rnn_target/n))+\")\")\n",
    "test_set_size= len(test_set)\n",
    "test_acc = percent(rnn_target/test_set_size)\n",
    "\n",
    "# dfa_from_rnn=generator_dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "true\n\n\npositive traces---> \n[]\n\n\nnegative traces---> \n[]\n\n\n\nLearning formula with depth 0\nlearned LTL formula: true\nLearning took:  0.05406618118286133  s\nNo positive counterexample found\nEQ test took  0.03304290771484375  s\nnew counterexample: a  should be rejected by implementation\n\n\npositive traces---> \n[]\n\n\nnegative traces---> \n['a']\n\n\n\n0  iteration complete\n\n\n\nLearning formula with depth 0\nlearned LTL formula: false\nLearning took:  0.05552482604980469  s\nEQ test took  0.0016529560089111328  s\nnew counterexample:   should be accepted by implementation\n\n\npositive traces---> \n['']\n\n\nnegative traces---> \n['a']\n\n\n\n1  iteration complete\n\n\n\nstart formula depth: 1\nincreasing formula depth to  2\nBefore normalization: (! x0)\nLearning formula with depth 1\nlearned LTL formula: (~ a)\nLearning took:  0.1160271167755127  s\nNo positive counterexample found\nEQ test took  0.07735514640808105  s\nnew counterexample: ba  should be rejected by implementation\n\n\npositive traces---> \n['']\n\n\nnegative traces---> \n['a', 'ba']\n\n\n\n2  iteration complete\n\n\n\nstart formula depth: 2\nincreasing formula depth to  3\nBefore normalization: (G (! x0))\nLearning formula with depth 2\nlearned LTL formula: (G (~ a))\nLearning took:  0.18654227256774902  s\nEQ test took  0.17908501625061035  s\n\n\nepsilon= 0.03 delta= 0.03 max_trace_length= 20\nquery: true\nfinal ltl:  (G (~ a))\nreturned counterexamples: ['a', '', 'ba']\n\nTime taken: 0.7097370624542236\noverall guided extraction time took: 0.1547470000000004\ngenerated counterexamples were: (format: (counterexample, counterexample generation time))\n\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nTime taken to extract lstar-dfa: 0.15596985816955566\nnumber of states of the dfa: 2\nreturned flag: True\nExplanation matches RNN: 100.0\nRNN matches ground truth: 100.0\nExplanation matches ground truth: 100.0\nLstar matches RNN: 100.0\nLstar matches ground truth: 100.0\ntarget query explanation status  test accuracy  rnn score  explanation score  explanation score on ground truth  extraction time revised delta revised epsilon counterexamples train size test size ltl_depth lstar_states  lstar explanation score  lstar explanation score on ground truth  lstar extraction time lstar_status\n G(~a)  true   (G (~ a))   True          100.0      100.0              100.0                              100.0         0.709737          None            None       [a, , ba]        991       248         2            2                    100.0                                    100.0                0.15597         True\n"
    }
   ],
   "source": [
    "timeout = 15\n",
    "maximum_sequence_length = 50\n",
    "maximum_formula_depth = 50\n",
    "epsilon = 0.05\n",
    "delta = 0.05\n",
    "\n",
    "# use a query LTL formula\n",
    "query_formula=\"true\"\n",
    "print(query_formula)\n",
    "query_dfa=ltlf2dfa.translate_ltl2dfa(alphabet=[character for character in alphabet],formula=query_formula, token=\"bal\")\n",
    "# print(query_dfa)\n",
    "\"\"\"  \n",
    "Create initial samples\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from RNNexplainer import Traces\n",
    "traces=Traces(rnn, alphabet, token=\"bal\")\n",
    "traces.label_from_network([])\n",
    "traces.write_in_file()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from PACTeacher.pac_teacher import PACTeacher as Teacher \n",
    "explainer=Explainer(alphabet=[character for character in alphabet], token=\"bal\")\n",
    "teacher = Teacher(dfa_from_rnn,epsilon=.03, delta=.03, max_trace_length=20, max_formula_depth=10, query_dfa=query_dfa)\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "start_time=time.time()\n",
    "from multiprocessing import Process, Queue\n",
    "explainer, flag= teacher.teach(explainer, traces, timeout = 2)\n",
    "end_time=time.time()\n",
    "\n",
    "\n",
    "print(\"\\n\\nepsilon=\", teacher.epsilon, \"delta=\", teacher.delta, \"max_trace_length=\", teacher.max_trace_length)\n",
    "print(\"query:\", query_formula)\n",
    "print(\"final ltl: \", explainer.ltl)\n",
    "\n",
    "fout=open(\"output/log.txt\", \"a\")\n",
    "fout.write(\"\\n\\nquery: \"+query_formula)\n",
    "fout.write(\"\\nfinal LTL: \"+ explainer.ltl)\n",
    "\n",
    "new_delta = None\n",
    "new_epsilon = None\n",
    "if(not flag):\n",
    "    fout.write(\" [incomplete]\")\n",
    "    print(\"incomplete formula\")\n",
    "    new_delta, new_epsilon = teacher.calculate_revised_delta_and_epsilon()\n",
    "    print(new_delta, new_epsilon)\n",
    "\n",
    "fout.write(\"\\n\\n\")\n",
    "\n",
    "print(\"returned counterexamples:\", teacher.returned_counterexamples)\n",
    "\n",
    "print(\"\\nTime taken:\", end_time-start_time)\n",
    "fout.close()\n",
    "\n",
    "\n",
    "fout=open(\"output/log.txt\", \"a\")\n",
    "\n",
    "\n",
    "# compare with dfa from lstar_algorithm\n",
    "start_time_lstar = time.time()\n",
    "dfa_lstar, lstar_flag = extract(rnn, query=query_dfa, max_trace_length=maximum_sequence_length, epsilon=delta,\n",
    "                            delta=delta, time_limit=10, initial_split_depth=10, starting_examples=[])\n",
    "end_time_lstar = time.time()\n",
    "\n",
    "dfa_lstar.draw_nicely(filename= target_formula+\":\"+query_formula)\n",
    "print(\"\\nTime taken to extract lstar-dfa:\", end_time_lstar-start_time_lstar)\n",
    "print(\"number of states of the dfa:\", len(dfa_lstar.Q))\n",
    "print(\"returned flag:\", lstar_flag)\n",
    "\n",
    "\n",
    "performance_explanation_with_rnn = performance_rnn_with_groundtruth = performance_explanation_with_groundtruth = 0\n",
    "lstar_performance_explanation_with_rnn = lstar_performance_explanation_with_groundtruth = 0\n",
    "\n",
    "test_set_size = 0\n",
    "\n",
    "for w in train_set:\n",
    "    if(query_dfa.classify_word(w)):\n",
    "        test_set_size += 1\n",
    "        verdict_rnn = dfa_from_rnn.classify_word(w)\n",
    "        verdict_target = generator_dfa.classify_word(w)\n",
    "        verdict_ltl = explainer.dfa.classify_word(w)\n",
    "        verdict_lstar = dfa_lstar.classify_word(w)\n",
    "\n",
    "        if verdict_rnn == verdict_ltl:\n",
    "            performance_explanation_with_rnn += 1\n",
    "        if verdict_rnn == verdict_target:\n",
    "            performance_rnn_with_groundtruth += 1\n",
    "        if verdict_ltl == verdict_target:\n",
    "            performance_explanation_with_groundtruth += 1\n",
    "        \n",
    "        if verdict_rnn == verdict_lstar:\n",
    "            lstar_performance_explanation_with_rnn += 1\n",
    "        if verdict_lstar == verdict_target:\n",
    "            lstar_performance_explanation_with_groundtruth += 1\n",
    "        \n",
    "\n",
    "if(test_set_size != 0):\n",
    "    print(\"Explanation matches RNN:\", str(\n",
    "        percent(performance_explanation_with_rnn/test_set_size)))\n",
    "\n",
    "    print(\"RNN matches ground truth:\", str(\n",
    "        percent(performance_rnn_with_groundtruth/test_set_size)))\n",
    "\n",
    "    print(\"Explanation matches ground truth:\", str(\n",
    "        percent(performance_explanation_with_groundtruth/test_set_size)))\n",
    "    \n",
    "    print(\"Lstar matches RNN:\", str(\n",
    "        percent(lstar_performance_explanation_with_rnn/test_set_size)))\n",
    "\n",
    "    print(\"Lstar matches ground truth:\", str(\n",
    "        percent(lstar_performance_explanation_with_groundtruth/test_set_size)))\n",
    "\n",
    "\n",
    "fout.close()\n",
    "\n",
    "# report in a pandas file\n",
    "result = pd.DataFrame(columns=['target',\n",
    "                                'query',\n",
    "                                'explanation',\n",
    "                                'status',\n",
    "                                'test accuracy',\n",
    "                                'rnn score',\n",
    "                                'explanation score',\n",
    "                                'explanation score on ground truth',\n",
    "                                'extraction time',\n",
    "                                'revised delta',\n",
    "                                'revised epsilon',\n",
    "                                'counterexamples',\n",
    "                                'train size',\n",
    "                                'test size',\n",
    "                                'ltl_depth',\n",
    "                                'lstar_states',\n",
    "                                'lstar explanation score',\n",
    "                                'lstar explanation score on ground truth',\n",
    "                                'lstar extraction time',\n",
    "                                'lstar_status'\n",
    "                                ])\n",
    "\n",
    "if(test_set_size != 0):\n",
    "    result = result.append(\n",
    "        {\n",
    "            'target': target_formula,\n",
    "            'query': query_formula,\n",
    "            'explanation': explainer.ltl,\n",
    "            'status': flag,\n",
    "            'test accuracy': test_acc,\n",
    "            'rnn score': percent(performance_rnn_with_groundtruth/test_set_size),\n",
    "            'explanation score': percent(performance_explanation_with_rnn/test_set_size),\n",
    "            'explanation score on ground truth': percent(performance_explanation_with_groundtruth/test_set_size),\n",
    "            'extraction time': end_time-start_time,\n",
    "            'revised delta': new_delta,\n",
    "            'revised epsilon': new_epsilon,\n",
    "            'counterexamples': teacher.returned_counterexamples,\n",
    "            'train size': len(train_set),\n",
    "            'test size': len(test_set),\n",
    "            \"ltl_depth\": explainer.formula_depth,\n",
    "            \"lstar_states\": len(dfa_lstar.Q),\n",
    "            'lstar explanation score': percent(lstar_performance_explanation_with_rnn/test_set_size),\n",
    "            'lstar explanation score on ground truth': percent(lstar_performance_explanation_with_groundtruth/test_set_size),\n",
    "            'lstar extraction time': end_time_lstar - start_time_lstar,\n",
    "            'lstar_status': lstar_flag\n",
    "                                \n",
    "        }, ignore_index=True\n",
    "    )\n",
    "else:\n",
    "    result = result.append(\n",
    "        {\n",
    "            'target': target_formula,\n",
    "            'query': query_formula,\n",
    "            'explanation': explainer.ltl,\n",
    "            'status': flag,\n",
    "            'test accuracy': test_acc,\n",
    "            'rnn score': None,\n",
    "            'explanation score': None,\n",
    "            'explanation score on ground truth': None,\n",
    "            'extraction time': end_time-start_time,\n",
    "            'revised delta': new_delta,\n",
    "            'revised epsilon': new_epsilon,\n",
    "            'counterexamples': teacher.returned_counterexamples,\n",
    "            'train size': len(train_set),\n",
    "            'test size': len(test_set),\n",
    "            'train size': len(train_set),\n",
    "            'test size': len(test_set),\n",
    "            \"ltl_depth\": explainer.formula_depth,\n",
    "            \"lstar_states\": len(dfa_lstar.Q),\n",
    "            'lstar explanation score': None,\n",
    "            'lstar explanation score on ground truth': None,\n",
    "            'lstar extraction time': end_time_lstar - start_time_lstar,\n",
    "            'lstar_status': lstar_flag\n",
    "            \n",
    "        }, ignore_index=True\n",
    "    )\n",
    "print(result.to_string(index=False))\n",
    "result.to_csv('output/result.csv', header=False, index=False, mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}