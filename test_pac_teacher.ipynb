{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from RNN2DFA.LSTM import LSTMNetwork\n",
    "# from GRU import GRUNetwork\n",
    "from RNN2DFA.RNNClassifier import RNNClassifier\n",
    "from RNN2DFA.Training_Functions import mixed_curriculum_train\n",
    "import Tomita_Grammars \n",
    "from RNN2DFA.Training_Functions import make_test_set,make_train_set_for_target\n",
    "from RNNexplainer import Explainer\n",
    "import pandas as pd\n",
    "import LTL2DFA as ltlf2dfa\n",
    "from RNN2DFA.Extraction import extract\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reber grammar\n",
    "from specific_examples import Reber_Grammar\n",
    "rg=Reber_Grammar()\n",
    "alphabet=rg.alphabet\n",
    "generator_dfa=rg\n",
    "sample_train_set=[]\n",
    "for i in range(100):\n",
    "    seq, _, _ = rg.get_one_example(maxLength=10)\n",
    "    sample_train_set.append(seq)\n",
    "    # print(rg.classify_word(rg.sequenceToWord(seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "email match\n"
    }
   ],
   "source": [
    "import specific_examples\n",
    "generator_dfa=specific_examples.Email()\n",
    "target_formula = generator_dfa.target_formula\n",
    "alphabet = generator_dfa.alphabet\n",
    "query_formulas = generator_dfa.query_formulas\n",
    "\n",
    "print(target_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loading from previously stored benchmarks\nout of  19235  sequences 9719  are positive. (percent:  0.505276839095399 )\nexamples per length: [1, 4, 16, 64, 200, 204, 219, 242, 285, 339, 375, 403, 416, 427, 428, 431, 432, 433, 432, 434, 434, 431, 434, 433, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434]\nsize of train set: 15388\nsize of test set: 3847\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def dict2lists(dictionary):\n",
    "    X,y=[],[]\n",
    "    for key in dictionary:\n",
    "        X.append(key)\n",
    "        y.append(dictionary[key])\n",
    "    return X,y\n",
    "\n",
    "def lists2dict(x,y):\n",
    "    # both x and y should have same length\n",
    "    assert len(x)==len(y), \"Error dimension\"\n",
    "    d={}\n",
    "    n=len(x)\n",
    "    for idx in range(n):\n",
    "        d[x[idx]]=y[idx]\n",
    "    return d\n",
    "\n",
    "# for each example, specify a different generating function\n",
    "file_name = \"benchmarks/\" + target_formula.replace(\" \", \"_\")+\".pkl\"\n",
    "\n",
    "if not os.path.isfile(file_name):\n",
    "\n",
    "    if(target_formula == \"balanced parentheses\"):\n",
    "\n",
    "        train_set = generator_dfa.get_balanced_parantheses_train_set(8000, 2, 50, max_train_samples_per_length=3000,\n",
    "                                                                     search_size_per_length=2000, lengths=[i for i in range(maximum_sequence_length+1)])\n",
    "\n",
    "    elif(target_formula == \"email match\"):\n",
    "\n",
    "        train_set = make_train_set_for_target(generator_dfa.classify_word, alphabet, lengths=[i for i in range(maximum_sequence_length+1)],\n",
    "                                              max_train_samples_per_length=1000,\n",
    "                                              search_size_per_length=3000, deviation=200)\n",
    "\n",
    "        # generate more examples that match the regular expression\n",
    "        matching_strings = generator_dfa.generate_matching_strings(\n",
    "            n=10800, max_length=50)\n",
    "        for string in matching_strings:\n",
    "            train_set[string] = True\n",
    "\n",
    "    elif(target_formula == \"alternating bit protocol\"):\n",
    "\n",
    "        train_set = make_train_set_for_target(generator_dfa.classify_word, alphabet, lengths=[i for i in range(maximum_sequence_length+1)],\n",
    "                                              max_train_samples_per_length=1000,\n",
    "                                              search_size_per_length=3000, deviation=250)\n",
    "\n",
    "        # generate more examples that match the regular expression\n",
    "        matching_strings = generator_dfa.generate_matching_strings(\n",
    "            n=105000, max_sequence_length=50)\n",
    "        for string in matching_strings:\n",
    "            train_set[string] = True\n",
    "    elif(target_formula == 'G(a->X(b))'):\n",
    "        train_set = make_train_set_for_target(generator_dfa.classify_word, alphabet, lengths=[i for i in range(maximum_sequence_length+1)],\n",
    "                                              max_train_samples_per_length=1000,\n",
    "                                              search_size_per_length=3000, deviation=20)\n",
    "\n",
    "    else:\n",
    "        train_set = make_train_set_for_target(generator_dfa.classify_word, alphabet, lengths=[i for i in range(maximum_sequence_length+1)],\n",
    "                                              max_train_samples_per_length=10000,\n",
    "                                              search_size_per_length=30000, deviation=20)\n",
    "\n",
    "    # now save the dataset to file\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        pickle.dump(train_set, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    # load the dataset\n",
    "    print(\"loading from previously stored benchmarks\")\n",
    "\n",
    "    def load_obj(name):\n",
    "        with open(name, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    train_set = load_obj(file_name)\n",
    "\n",
    "# print ratio\n",
    "cnt = 0\n",
    "examples_per_length=[0 for i in range(51)]\n",
    "for key in train_set:\n",
    "    if(train_set[key]):\n",
    "        cnt += 1\n",
    "    examples_per_length[len(key)] += 1\n",
    "\n",
    "total_samples = len(train_set) \n",
    "print(\"out of \", total_samples, \" sequences\", cnt , \" are positive. (percent: \", float(cnt/total_samples), \")\")\n",
    "print(\"examples per length:\", examples_per_length)\n",
    "    \n",
    "# split train:test\n",
    "X, y = dict2lists(train_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "train_set = lists2dict(X_train, y_train)\n",
    "test_set = lists2dict(X_test, y_test)\n",
    "print(\"size of train set:\", len(train_set))\n",
    "print(\"size of test set:\", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "size of train set: 15389\nsize of test set: 3847\n"
    }
   ],
   "source": [
    "# intentionally pushing \"\" (empty string) in train_set\n",
    "if('' not in train_set):\n",
    "    train_set['']=test_set['']\n",
    "print(\"size of train set:\", len(train_set))\n",
    "print(\"size of test set:\", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "email match\nout of  15389  sequences 7803  are positive. (percent:  0.5070504906101762 )\nexamples per length: [1, 3, 13, 52, 162, 156, 188, 203, 218, 269, 303, 323, 352, 338, 344, 345, 326, 360, 347, 349, 350, 340, 356, 337, 342, 356, 345, 349, 340, 346, 344, 353, 347, 349, 343, 346, 367, 351, 359, 338, 356, 332, 339, 341, 335, 345, 351, 343, 342, 356, 339]\nEmpty string status: False\nsize of train set: 12311\nsize of test set: 3078\nconfigurations: layers:  3 hidden dimension:  10 input dim:  3 network:  <class 'RNN2DFA.LSTM.LSTMNetwork'> stop threshold:  0.0005\nThe dy.parameter(...) call is now DEPRECATED.\n        There is no longer need to explicitly add parameters to the computation graph.\n        Any used parameter will be added automatically.\nloading already saved model\ntesting on train set, i.e. test set is train set\nrnn score against target on test set:                              3078 (100.0)\n"
    }
   ],
   "source": [
    "fout=open(\"output/log.txt\", \"a\")\n",
    "fout.write(\".........................................................................\\n\")\n",
    "fout.write(\"Target: \"+ target_formula)\n",
    "print(target_formula)\n",
    "fout.write(\"\\n\")\n",
    "fout.close()\n",
    "\n",
    "num_layers = 3\n",
    "num_hidden_dim = 10\n",
    "input_dim = 3\n",
    "iterations = 1\n",
    "stop_threshold = 0.0005\n",
    "RNNClass = LSTMNetwork\n",
    "\n",
    "\n",
    "# print ratio\n",
    "cnt = 0\n",
    "examples_per_length = [0 for i in range(51)]\n",
    "for key in train_set:\n",
    "    if(train_set[key]):\n",
    "        cnt += 1\n",
    "\n",
    "    examples_per_length[len(key)] += 1\n",
    "\n",
    "total_samples = len(train_set)\n",
    "print(\"out of \", total_samples, \" sequences\", cnt,\n",
    "      \" are positive. (percent: \", float(cnt/total_samples), \")\")\n",
    "print(\"examples per length:\", examples_per_length)\n",
    "\n",
    "# split train:test\n",
    "X, y = dict2lists(train_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "train_set = lists2dict(X_train, y_train)\n",
    "test_set = lists2dict(X_test, y_test)\n",
    "train_set_size = len(train_set)\n",
    "test_set_size = len(test_set)\n",
    "\n",
    "# intentionally pushing \"\" (empty string) in train_set\n",
    "if('' not in train_set):\n",
    "    train_set[''] = test_set['']\n",
    "    print(\"Empty string status:\", train_set[''])\n",
    "else:\n",
    "    print(\"Empty string was already included in train set\")\n",
    "    print(\"Empty string status:\", train_set[''])\n",
    "\n",
    "print(\"size of train set:\", train_set_size)\n",
    "print(\"size of test set:\", test_set_size)\n",
    "\n",
    "print(\"configurations: layers: \", num_layers,\n",
    "          \"hidden dimension: \", num_hidden_dim,\n",
    "          \"input dim: \", input_dim,\n",
    "          \"network: \", RNNClass,\n",
    "          \"stop threshold: \", stop_threshold)\n",
    "\n",
    "\n",
    "# define rnn\n",
    "rnn = RNNClassifier(alphabet, num_layers=num_layers,\n",
    "                    hidden_dim=num_hidden_dim, RNNClass=RNNClass, input_dim=input_dim, target=target_formula)\n",
    "\n",
    "try:\n",
    "    # train the model\n",
    "    if not os.path.isfile(\"model/\"+target_formula+\".model\"):\n",
    "        mixed_curriculum_train(rnn, train_set, stop_threshold=stop_threshold)\n",
    "        rnn.save_model()\n",
    "    else:\n",
    "        print(\"loading already saved model\")\n",
    "        rnn.load_model()\n",
    "except:\n",
    "    print(\"Training error: however moving on as life also goes on\" )\n",
    "    \n",
    "rnn.renew()\n",
    "dfa_from_rnn = rnn\n",
    "# statistics\n",
    "\n",
    "def percent(num, digits=2):\n",
    "    tens = pow(10, digits)\n",
    "    return int(100*num*tens)/tens\n",
    "\n",
    "print(\"testing on train set, i.e. test set is train set\")\n",
    "# we're printing stats on the train set for now, but you can define other test sets by using\n",
    "# make_train_set_for_target\n",
    "\n",
    "pos = 0\n",
    "rnn_target = 0\n",
    "for w in test_set:\n",
    "    if generator_dfa.classify_word(w):\n",
    "        pos += 1\n",
    "\n",
    "    if dfa_from_rnn.classify_word(w) == generator_dfa.classify_word(w):\n",
    "        rnn_target += 1\n",
    "test_acc = percent(rnn_target/test_set_size)\n",
    "print(\"rnn score against target on test set:                             \",\n",
    "        rnn_target, \"(\"+str(test_acc)+\")\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "~F(a)\n\n\npositive traces---> \n[]\n\n\nnegative traces---> \n[]\n\n\n\nLearning formula with depth 0\nNumber of subformulas: 1\nlearned LTL formula: false\nLearning took:  0.05129075050354004  s\nEQ test took  0.2297983169555664  s\nnew counterexample: mpdpmppdpp  should be accepted by implementation\n\n\npositive traces---> \n['mpdpmppdpp']\n\n\nnegative traces---> \n[]\n\n\n\n0  iteration complete\n\n\n\nLearning formula with depth 0\nNumber of subformulas: 1\nlearned LTL formula: true\nLearning took:  0.04643583297729492  s\nEQ test took  0.0034830570220947266  s\nnew counterexample:   should be rejected by implementation\n\n\npositive traces---> \n['mpdpmppdpp']\n\n\nnegative traces---> \n['']\n\n\n\n1  iteration complete\n\n\n\nstart formula depth: 1\nBefore normalization: x2\nLearning formula with depth 0\nNumber of subformulas: 1\nlearned LTL formula: m\nLearning took:  0.08731317520141602  s\nEQ test took  0.18093585968017578  s\nnew counterexample: m  should be rejected by implementation\n\n\npositive traces---> \n['mpdpmppdpp']\n\n\nnegative traces---> \n['', 'm']\n\n\n\n2  iteration complete\n\n\n\nstart formula depth: 1\nincreasing formula depth to  2\nBefore normalization: (F x1)\nLearning formula with depth 1\nNumber of subformulas: 2\nlearned LTL formula: (F d)\nLearning took:  0.15160202980041504  s\nNo positive counterexample found\nEQ test took  0.0921788215637207  s\nnew counterexample: d  should be rejected by implementation\n\n\npositive traces---> \n['mpdpmppdpp']\n\n\nnegative traces---> \n['', 'm', 'd']\n\n\n\n3  iteration complete\n\n\n\nstart formula depth: 2\nBefore normalization: (X x3)\nLearning formula with depth 1\nNumber of subformulas: 2\nlearned LTL formula: (X p)\nLearning took:  0.13755512237548828  s\nEQ test took  0.16210103034973145  s\nnew counterexample: pmpmppdp  should be accepted by implementation\n\n\npositive traces---> \n['mpdpmppdpp', 'pmpmppdp']\n\n\nnegative traces---> \n['', 'm', 'd']\n\n\n\n4  iteration complete\n\n\n\nstart formula depth: 2\nBefore normalization: (F x3)\nLearning formula with depth 1\nNumber of subformulas: 2\nlearned LTL formula: (F p)\nLearning took:  0.1696031093597412  s\nEQ test took  0.10148978233337402  s\nnew counterexample: p  should be rejected by implementation\n\n\npositive traces---> \n['mpdpmppdpp', 'pmpmppdp']\n\n\nnegative traces---> \n['', 'm', 'd', 'p']\n\n\n\n5  iteration complete\n\n\n\nstart formula depth: 2\nincreasing formula depth to  3\nBefore normalization: (F (X x1))\nLearning formula with depth 2\nNumber of subformulas: 3\nlearned LTL formula: (F (X d))\nLearning took:  0.4392211437225342  s\nNo positive counterexample found\nEQ test took  0.1293787956237793  s\nnew counterexample: dd  should be rejected by implementation\n\n\npositive traces---> \n['mpdpmppdpp', 'pmpmppdp']\n\n\nnegative traces---> \n['', 'm', 'd', 'p', 'dd']\n\n\n\n6  iteration complete\n\n\n\nstart formula depth: 3\nBefore normalization: (F (X x2))\nLearning formula with depth 2\nNumber of subformulas: 3\nlearned LTL formula: (F (X m))\nLearning took:  0.37476110458374023  s\nEQ test took  0.12407207489013672  s\nnew counterexample: pppppdp  should be accepted by implementation\n\n\npositive traces---> \n['mpdpmppdpp', 'pmpmppdp', 'pppppdp']\n\n\nnegative traces---> \n['', 'm', 'd', 'p', 'dd']\n\n\n\n7  iteration complete\n\n\n\nstart formula depth: 3\nBefore normalization: (F (X x3))\nLearning formula with depth 2\nNumber of subformulas: 3\nlearned LTL formula: (F (X p))\nLearning took:  0.44425487518310547  s\nEQ test took  0.17136120796203613  s\nnew counterexample: ap  should be rejected by implementation\n\n\npositive traces---> \n['mpdpmppdpp', 'pmpmppdp', 'pppppdp']\n\n\nnegative traces---> \n['', 'm', 'd', 'p', 'dd', 'ap']\n\n\n\n8  iteration complete\n\n\n\nstart formula depth: 3\nincreasing formula depth to  4\nBefore normalization: ((X x3) U (X (X x3)))\nLearning formula with depth 3\nNumber of subformulas: 4\nlearned LTL formula: ((X p) U (X (X p)))\nLearning took:  1.3247439861297607  s\nEQ test took  0.3696770668029785  s\nnew counterexample: mmmpmdp  should be accepted by implementation\n\n\npositive traces---> \n['mpdpmppdpp', 'pmpmppdp', 'pppppdp', 'mmmpmdp']\n\n\nnegative traces---> \n['', 'm', 'd', 'p', 'dd', 'ap']\n\n\n\n9  iteration complete\n\n\n\nstart formula depth: 4\nBefore normalization: ((F x1) & (! x1))\nLearning formula with depth 2\nNumber of subformulas: 4\nlearned LTL formula: ((~ d) & (F d))\nLearning took:  1.0748729705810547  s\nEQ test took  0.15460491180419922  s\nnew counterexample: md  should be rejected by implementation\n\n\npositive traces---> \n['mpdpmppdpp', 'pmpmppdp', 'pppppdp', 'mmmpmdp']\n\n\nnegative traces---> \n['', 'm', 'd', 'p', 'dd', 'ap', 'md']\n\n\n\n10  iteration complete\n\n\n\nstart formula depth: 4\nBefore normalization: (X (F (X x1)))\nLearning formula with depth 3\nNumber of subformulas: 4\nlearned LTL formula: (X (F (X d)))\nLearning took:  1.1843202114105225  s\nNo positive counterexample found\nEQ test took  0.20572781562805176  s\nnew counterexample: mad  should be rejected by implementation\n\n\npositive traces---> \n['mpdpmppdpp', 'pmpmppdp', 'pppppdp', 'mmmpmdp']\n\n\nnegative traces---> \n['', 'm', 'd', 'p', 'dd', 'ap', 'md', 'mad']\n\n\n\n11  iteration complete\n\n\n\nstart formula depth: 4\nBefore normalization: (X (F (X x3)))\nLearning formula with depth 3\nNumber of subformulas: 4\nlearned LTL formula: (X (F (X p)))\nLearning took:  1.3055479526519775  s\nNo positive counterexample found\nEQ test took  0.21641016006469727  s\nnew counterexample: dap  should be rejected by implementation\n\n\npositive traces---> \n['mpdpmppdpp', 'pmpmppdp', 'pppppdp', 'mmmpmdp']\n\n\nnegative traces---> \n['', 'm', 'd', 'p', 'dd', 'ap', 'md', 'mad', 'dap']\n\n\n\n12  iteration complete\n\n\n\nstart formula depth: 4\n\n\nepsilon= 0.03 delta= 0.03 max_trace_length= 20\nquery: ~F(a)\nfinal ltl:  (X (F (X p)))\nincomplete formula\nNumber of samples: 418\nNumber of counterexamples returned: 415\n11045055.783138812 6.604683780892249\nreturned counterexamples: ['mpdpmppdpp', '', 'm', 'd', 'pmpmppdp', 'p', 'dd', 'pppppdp', 'ap', 'mmmpmdp', 'md', 'mad', 'dap']\n\nTime taken: 11.015017986297607\n\n\n\n\n\nReturned counterexample is: mmpmdp  which should be classified:  True\nReturned counterexample is: apmppmmppdp  which should be classified:  False\nReturned counterexample is: ppmpmdp  which should be classified:  True\nReturned counterexample is: pamdp  which should be classified:  False\nReturned counterexample is: mpdpp  which should be classified:  False\nReturned counterexample is: papdp  which should be classified:  False\nInterrupted due to time limit\ndoing minimization from  112  states to  112  states\noverall guided extraction time took: 10.080150000000003\ngenerated counterexamples were: (format: (counterexample, counterexample generation time))\n('mmpmdp', 0.30105600000000265)\n('apmppmmppdp', 0.3243880000000132)\n('ppmpmdp', 0.35308700000000215)\n('pamdp', 0.25634600000000773)\n('mpdpp', 0.48826700000000756)\n('papdp', 0.5305469999999985)\ndoing minimization from  112  states to  112  states\n\nTime taken to extract lstar-dfa: 10.355391025543213\nreturned flag: False\ntransitions:->\nnumber of states of the dfa: 112\nExplanation matches RNN: 2.7\nRNN matches ground truth: 99.98\nExplanation matches ground truth: 2.7\nLstar matches RNN: 49.18\nLstar matches ground truth: 49.18\n"
    }
   ],
   "source": [
    "timeout = 10\n",
    "maximum_sequence_length = 50\n",
    "maximum_formula_depth = 50\n",
    "epsilon = 0.05\n",
    "delta = 0.05\n",
    "\n",
    "# use a query LTL formula\n",
    "query_formula=\"~F(a)\"\n",
    "print(query_formula)\n",
    "query_dfa=ltlf2dfa.translate_ltl2dfa(alphabet=[character for character in alphabet],formula=query_formula, token=\"bal\")\n",
    "# print(query_dfa)\n",
    "\"\"\"  \n",
    "Create initial samples\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from RNNexplainer import Traces\n",
    "traces=Traces(rnn, alphabet, token=\"bal\")\n",
    "traces.label_from_network([])\n",
    "traces.write_in_file()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from PACTeacher.pac_teacher import PACTeacher as Teacher \n",
    "explainer=Explainer(alphabet=[character for character in alphabet], token=\"bal\")\n",
    "teacher = Teacher(dfa_from_rnn,epsilon=.03, delta=.03, max_trace_length=20, max_formula_depth=10, query_dfa=query_dfa)\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "start_time=time.time()\n",
    "from multiprocessing import Process, Queue\n",
    "explainer, flag= teacher.teach(explainer, traces, timeout = 2)\n",
    "end_time=time.time()\n",
    "\n",
    "\n",
    "print(\"\\n\\nepsilon=\", teacher.epsilon, \"delta=\", teacher.delta, \"max_trace_length=\", teacher.max_trace_length)\n",
    "print(\"query:\", query_formula)\n",
    "print(\"final ltl: \", explainer.ltl)\n",
    "\n",
    "fout=open(\"output/log.txt\", \"a\")\n",
    "fout.write(\"\\n\\nquery: \"+query_formula)\n",
    "fout.write(\"\\nfinal LTL: \"+ explainer.ltl)\n",
    "\n",
    "new_delta = None\n",
    "new_epsilon = None\n",
    "if(not flag):\n",
    "    fout.write(\" [incomplete]\")\n",
    "    print(\"incomplete formula\")\n",
    "    new_delta, new_epsilon = teacher.calculate_revised_delta_and_epsilon()\n",
    "    print(new_delta, new_epsilon)\n",
    "\n",
    "fout.write(\"\\n\\n\")\n",
    "\n",
    "print(\"returned counterexamples:\", teacher.returned_counterexamples)\n",
    "\n",
    "print(\"\\nTime taken:\", end_time-start_time)\n",
    "fout.close()\n",
    "\n",
    "\n",
    "fout=open(\"output/log.txt\", \"a\")\n",
    "\n",
    "run_lstar = True\n",
    "if(run_lstar):\n",
    "        print(\"\\n\\n\\n\\n\")\n",
    "        # compare with dfa from lstar_algorithm\n",
    "        dfa_from_rnn.renew()\n",
    "        start_time_lstar = time.time()\n",
    "        dfa_lstar, lstar_flag = extract(rnn, query=query_dfa, max_trace_length=maximum_sequence_length, epsilon=delta,\n",
    "                                        delta=delta, time_limit=timeout, initial_split_depth=10, starting_examples=[])\n",
    "        end_time_lstar = time.time()\n",
    "\n",
    "        dfa_lstar.draw_nicely(\n",
    "            filename=target_formula+\":\"+query_formula+\"_\"+str(epsilon)+\"_\"+str(delta))\n",
    "        dfa_lstar = dfa_lstar.minimize_()\n",
    "        dfa_lstar.draw_nicely(\n",
    "            filename=target_formula+\":\"+query_formula+\"_\"+str(epsilon)+\"_\"+str(delta))\n",
    "\n",
    "        \n",
    "        print(\"\\nTime taken to extract lstar-dfa:\",\n",
    "                end_time_lstar-start_time_lstar)\n",
    "        print(\"returned flag:\", lstar_flag)\n",
    "        print(\"transitions:->\")\n",
    "        # print(dfa_lstar.delta)\n",
    "        num_lstar_states = len(dfa_lstar.Q)\n",
    "        print(\"number of states of the dfa:\", num_lstar_states)\n",
    "\n",
    "\n",
    "performance_explanation_with_rnn = performance_rnn_with_groundtruth = performance_explanation_with_groundtruth = 0\n",
    "lstar_performance_explanation_with_rnn = lstar_performance_explanation_with_groundtruth = 0\n",
    "\n",
    "test_set_size = 0\n",
    "for w in train_set:\n",
    "\n",
    "    \n",
    "\n",
    "    dfa_from_rnn.renew()\n",
    "\n",
    "    test_set_size += 1\n",
    "    verdict_rnn = dfa_from_rnn.classify_word(w)\n",
    "    verdict_target = generator_dfa.classify_word(w)\n",
    "    verdict_ltl = explainer.dfa.classify_word(w)\n",
    "    verdict_query = query_dfa.classify_word(w)\n",
    "\n",
    "    if(run_lstar):\n",
    "        verdict_lstar = dfa_lstar.classify_word(w)\n",
    "\n",
    "    if (verdict_rnn and verdict_query) == verdict_ltl:\n",
    "        performance_explanation_with_rnn += 1\n",
    "    if verdict_rnn == verdict_target:\n",
    "        performance_rnn_with_groundtruth += 1\n",
    "    if verdict_ltl == (verdict_target and verdict_query):\n",
    "        performance_explanation_with_groundtruth += 1\n",
    "    if(run_lstar):\n",
    "        if (verdict_rnn and verdict_query) == verdict_lstar:\n",
    "            lstar_performance_explanation_with_rnn += 1\n",
    "        if verdict_lstar == (verdict_target and verdict_query):\n",
    "            lstar_performance_explanation_with_groundtruth += 1\n",
    "\n",
    "if(test_set_size != 0):\n",
    "    print(\"Explanation matches RNN:\", str(\n",
    "        percent(performance_explanation_with_rnn/test_set_size)))\n",
    "\n",
    "    print(\"RNN matches ground truth:\", str(\n",
    "        percent(performance_rnn_with_groundtruth/test_set_size)))\n",
    "\n",
    "    print(\"Explanation matches ground truth:\", str(\n",
    "        percent(performance_explanation_with_groundtruth/test_set_size)))\n",
    "\n",
    "    if(run_lstar):\n",
    "        print(\"Lstar matches RNN:\", str(\n",
    "            percent(lstar_performance_explanation_with_rnn/test_set_size)))\n",
    "\n",
    "        print(\"Lstar matches ground truth:\", str(\n",
    "            percent(lstar_performance_explanation_with_groundtruth/test_set_size)))\n",
    "\n",
    "fout.close()\n",
    "\n",
    "if(not run_lstar):\n",
    "    num_lstar_states = None\n",
    "    start_time_lstar = 0\n",
    "    end_time_lstar = 0\n",
    "    lstar_performance_explanation_with_rnn = 0\n",
    "    lstar_performance_explanation_with_groundtruth = 0\n",
    "    lstar_flag = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}