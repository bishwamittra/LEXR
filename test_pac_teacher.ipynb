{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from RNN2DFA.LSTM import LSTMNetwork\n",
    "# from GRU import GRUNetwork\n",
    "from RNN2DFA.RNNClassifier import RNNClassifier\n",
    "from RNN2DFA.Training_Functions import mixed_curriculum_train\n",
    "import Tomita_Grammars \n",
    "from lstar_extraction.Training_Functions import make_test_set,make_train_set_for_target\n",
    "from RNNexplainer import Explainer\n",
    "import pandas as pd\n",
    "import LTL2DFA as ltlf2dfa\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from specific_examples import Alternating_Bit_Protocol\n",
    "abp=Alternating_Bit_Protocol()\n",
    "generator_dfa=abp.dfa\n",
    "target_formula=abp.target_formula\n",
    "alphabet=generator_dfa.alphabet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "DFA:->\n - alphabet: ['a', 'b', 'c']\n - Q: [1, 2, 3, 4]\n - q0: 1\n - F: [4]\n - delta: {1: {'000': 2, '001': 2, '010': 2, '011': 2, '100': 3, '101': 3, '110': 3, '111': 3}, 2: {'000': 2, '001': 2, '010': 2, '011': 2, '100': 3, '101': 3, '110': 3, '111': 3}, 3: {'000': 2, '001': 2, '010': 4, '011': 4, '100': 3, '101': 3, '110': 4, '111': 4}, 4: {'000': 4, '001': 4, '010': 4, '011': 4, '100': 4, '101': 4, '110': 4, '111': 4}}\n - is_singleton_graph: False\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# make training set on grammars\n",
    "# target = Tomita_Grammars.tomita_email\n",
    "# alphabet = \"pqradmn\"\n",
    "# generator_dfa.classify_word=target\n",
    "# target_formula=\"mail string match\"\n",
    "\n",
    "\n",
    "# use a dfa to generate training set\n",
    "target_formula=\"F(a & X(b))\"\n",
    "alphabet=\"abc\"\n",
    "fout=open(\"output/log.txt\", \"a\")\n",
    "fout.write(\".........................................................................\\n\")\n",
    "fout.write(\"Target: \"+ target_formula)\n",
    "fout.write(\"\\n\")\n",
    "fout.close()\n",
    "import LTL2DFA as ltlf2dfa\n",
    "generator_dfa=ltlf2dfa.translate_ltl2dfa(alphabet=[character for character in alphabet],formula=target_formula)\n",
    "print(generator_dfa)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(train_set)\n",
    "# print(\"\\n\\nPositive examples:\")\n",
    "# for key in train_set:\n",
    "#     if(train_set[key]):\n",
    "#         print(key)\n",
    "# print(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "made train set of size: 2213 , of which positive examples: 1254\n"
    }
   ],
   "source": [
    "# make training set\n",
    "train_set = make_train_set_for_target(generator_dfa.classify_word,alphabet,max_train_samples_per_length=100,search_size_per_length=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The dy.parameter(...) call is now DEPRECATED.\n        There is no longer need to explicitly add parameters to the computation graph.\n        Any used parameter will be added automatically.\ncurrent average loss is:  0.0021303590091186738\nclassification loss on last batch was: 0.000484731609962767\ntesting on train set, i.e. test set is train set\ntest set size: 2213\nof which positive: 1254 (56.66)\nrnn score against target on test set:                              2213 (100.0)\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# define rnn\n",
    "rnn = RNNClassifier(alphabet,num_layers=1,hidden_dim=10,RNNClass = LSTMNetwork)\n",
    "\n",
    "\n",
    "# train the model\n",
    "mixed_curriculum_train(rnn,train_set,stop_threshold = 0.0005)\n",
    "rnn.renew()  \n",
    "dfa_from_rnn=rnn \n",
    "# statistics\n",
    "\n",
    "def percent(num,digits=2):\n",
    "    tens = pow(10,digits)\n",
    "    return int(100*num*tens)/tens\n",
    "\n",
    "test_set = train_set \n",
    "print(\"testing on train set, i.e. test set is train set\")\n",
    "# we're printing stats on the train set for now, but you can define other test sets by using\n",
    "# make_train_set_for_target\n",
    "\n",
    "n = len(test_set)\n",
    "print(\"test set size:\", n)\n",
    "pos = len([w for w in test_set if generator_dfa.classify_word(w)])\n",
    "print(\"of which positive:\",pos,\"(\"+str(percent(pos/n))+\")\")\n",
    "rnn_target = len([w for w in test_set if dfa_from_rnn.classify_word(w)==generator_dfa.classify_word(w)])\n",
    "print(\"rnn score against target on test set:                             \",rnn_target,\"(\"+str(percent(rnn_target/n))+\")\")\n",
    "\n",
    "# dfa_from_rnn=generator_dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\npositive traces---> \n[]\n\n\nnegative traces---> \n[]\n\n\n\nlearned LTL formula: true\nnew counterexample:   should be rejected by implementation\n\n\npositive traces---> \n[]\n\n\nnegative traces---> \n['']\n\n\n\n0  iteration complete\n\n\n\nlearned LTL formula: false\nnew counterexample: ab  should be accepted by implementation\n\n\npositive traces---> \n['ab']\n\n\nnegative traces---> \n['']\n\n\n\n1  iteration complete\n\n\n\nstart formula depth: 1\nlearned LTL formula: a\nnew counterexample: a  should be rejected by implementation\n\n\npositive traces---> \n['ab']\n\n\nnegative traces---> \n['', 'a']\n\n\n\n2  iteration complete\n\n\n\nstart formula depth: 1\nlearned LTL formula: (X b)\nnew counterexample: aab  should be accepted by implementation\n\n\npositive traces---> \n['ab', 'aab']\n\n\nnegative traces---> \n['', 'a']\n\n\n\n3  iteration complete\n\n\n\nstart formula depth: 2\nlearned LTL formula: (F b)\nnew counterexample: b  should be rejected by implementation\n\n\npositive traces---> \n['ab', 'aab']\n\n\nnegative traces---> \n['', 'a', 'b']\n\n\n\n4  iteration complete\n\n\n\nstart formula depth: 2\nlearned LTL formula: (F (X b))\nNo positive counterexample found\nnew counterexample: bb  should be rejected by implementation\n\n\npositive traces---> \n['ab', 'aab']\n\n\nnegative traces---> \n['', 'a', 'b', 'bb']\n\n\n\n5  iteration complete\n\n\n\nstart formula depth: 3\nlearned LTL formula: (a & (a U b))\nnew counterexample: cab  should be accepted by implementation\n\n\npositive traces---> \n['ab', 'aab', 'cab']\n\n\nnegative traces---> \n['', 'a', 'b', 'bb']\n\n\n\n6  iteration complete\n\n\n\nstart formula depth: 4\nlearned LTL formula: ((~ b) & (F b))\nnew counterexample: cb  should be rejected by implementation\n\n\npositive traces---> \n['ab', 'aab', 'cab']\n\n\nnegative traces---> \n['', 'a', 'b', 'bb', 'cb']\n\n\n\n7  iteration complete\n\n\n\nstart formula depth: 4\nlearned LTL formula: ((a U (~ a)) & ((~ a) U a))\nNo positive counterexample found\nnew counterexample: ba  should be rejected by implementation\n\n\npositive traces---> \n['ab', 'aab', 'cab']\n\n\nnegative traces---> \n['', 'a', 'b', 'bb', 'cb', 'ba']\n\n\n\n8  iteration complete\n\n\n\nstart formula depth: 5\nlearned LTL formula: (F (a & (F (~ a))))\nNo positive counterexample found\nnew counterexample: ac  should be rejected by implementation\n\n\npositive traces---> \n['ab', 'aab', 'cab']\n\n\nnegative traces---> \n['', 'a', 'b', 'bb', 'cb', 'ba', 'ac']\n\n\n\n9  iteration complete\n\n\n\nstart formula depth: 5\nlearned LTL formula: ((F b) U ((F b) & a))\nNo positive counterexample found\nnew counterexample: acb  should be rejected by implementation\n\n\npositive traces---> \n['ab', 'aab', 'cab']\n\n\nnegative traces---> \n['', 'a', 'b', 'bb', 'cb', 'ba', 'ac', 'acb']\n\n\n\n10  iteration complete\n\n\n\nstart formula depth: 5\nlearned LTL formula: (F ((X b) & a))\n\n\nepsilon= 0.05 delta= 0.05 max_trace_length= 20\nquery: F(a)\nfinal ltl:  (F ((X b) & a))\n\nTime taken: 7.177111864089966\nextracted LTL score against rnn on test set:                       2213 (100.0)\nextracted LTL score against target on rnn's test set:              2213 (100.0)\nextracted LTL score against rnn on test set (with query):          2213 (100.0)\nextracted LTL score against target on rnn's test set (with query): 2213 (100.0)\n      target query      explanation status  rnn score  explanation score  explanation score on ground truth  extraction time\n F(a & X(b))  F(a)  (F ((X b) & a))   True      100.0              100.0                              100.0         7.177112\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# use a query LTL formula\n",
    "query_formula=\"F(a)\"\n",
    "query_dfa=ltlf2dfa.translate_ltl2dfa(alphabet=[character for character in alphabet],formula=query_formula)\n",
    "\n",
    "\"\"\"  \n",
    "Create initial samples\n",
    "\"\"\"\n",
    "\n",
    "test_set=[]\n",
    "if(query_dfa is None):\n",
    "    query_formula=None\n",
    "    test_set=make_test_set(alphabet)\n",
    "    raise SystemError\n",
    "\n",
    "\n",
    "from RNNexplainer import Traces\n",
    "traces=Traces(rnn, alphabet)\n",
    "traces.label_from_network(test_set)\n",
    "traces.write_in_file()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from PACTeacher.pac_teacher import PACTeacher as Teacher \n",
    "explainer=Explainer(alphabet=[character for character in alphabet])\n",
    "teacher = Teacher(dfa_from_rnn,epsilon=.05, delta=.05, max_trace_length=20, max_formula_depth=10, query_dfa=query_dfa)\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "start_time=time.time()\n",
    "from multiprocessing import Process, Queue\n",
    "explainer, flag= teacher.teach(explainer, traces, timeout = 15)\n",
    "end_time=time.time()\n",
    "\n",
    "\n",
    "print(\"\\n\\nepsilon=\", teacher.epsilon, \"delta=\", teacher.delta, \"max_trace_length=\", teacher.max_trace_length)\n",
    "print(\"query:\", query_formula)\n",
    "print(\"final ltl: \", explainer.ltl)\n",
    "\n",
    "fout=open(\"output/log.txt\", \"a\")\n",
    "fout.write(\"\\n\\nquery: \"+query_formula)\n",
    "fout.write(\"\\nfinal LTL: \"+ explainer.ltl)\n",
    "if(not flag):\n",
    "    fout.write(\" [incomplete]\")\n",
    "    print(\"incomplete formula\")\n",
    "fout.write(\"\\n\\n\")\n",
    "\n",
    "print(\"\\nTime taken:\", end_time-start_time)\n",
    "fout.close()\n",
    "\n",
    "\n",
    "test_set = train_set \n",
    "fout=open(\"output/log.txt\", \"a\")\n",
    "# fout.write(\"rnn score against target on test set:                             \"+str(rnn_target)+\"(\"+str(percent(rnn_target/n))+\")\")\n",
    "# fout.write(\"\\n\")\n",
    "\n",
    "performance_ltl = len([w for w in test_set if dfa_from_rnn.classify_word(w)==explainer.dfa.classify_word(w)])\n",
    "print(\"extracted LTL score against rnn on test set:                      \",performance_ltl,\"(\"+str(percent(performance_ltl/n))+\")\")\n",
    "performance_ltl_with_target = len([w for w in test_set if explainer.dfa.classify_word(w)==generator_dfa.classify_word(w)])\n",
    "print(\"extracted LTL score against target on rnn's test set:             \",performance_ltl_with_target,\"(\"+str(percent(performance_ltl_with_target/n))+\")\")\n",
    "\n",
    "performance_ltl = len([w for w in test_set if (dfa_from_rnn.classify_word(w)and query_dfa.classify_word(w)) ==explainer.dfa.classify_word(w)])\n",
    "print(\"extracted LTL score against rnn on test set (with query):         \",performance_ltl,\"(\"+str(percent(performance_ltl/n))+\")\")\n",
    "# fout.write(\"extracted LTL score against rnn on test set (with query):         \"+str(performance_ltl)+\"(\"+str(percent(performance_ltl/n))+\")\\n\")\n",
    "performance_ltl_with_target = len([w for w in test_set if explainer.dfa.classify_word(w)== (generator_dfa.classify_word(w) and query_dfa.classify_word(w))])\n",
    "print(\"extracted LTL score against target on rnn's test set (with query):\",performance_ltl_with_target,\"(\"+str(percent(performance_ltl_with_target/n))+\")\")\n",
    "\n",
    "# fout.write(\"extracted LTL score against target on rnn's test set (with query):\"+str(performance_ltl_with_target)+\"(\"+str(percent(performance_ltl_with_target/n))+\")\\n\")\n",
    "fout.close()\n",
    "\n",
    "\n",
    "# report in a pandas file\n",
    "result = pd.DataFrame(columns=['target', \n",
    "                                'query', \n",
    "                                'explanation', \n",
    "                                'status', \n",
    "                                'rnn score', \n",
    "                                'explanation score', \n",
    "                                'explanation score on ground truth',\n",
    "                                'extraction time'\n",
    "                                ])\n",
    "\n",
    "result = result.append(\n",
    "    {\n",
    "        'target':target_formula,\n",
    "        'query':query_formula,\n",
    "        'explanation':explainer.ltl,\n",
    "        'status':flag,\n",
    "        'rnn score':percent(rnn_target/n),\n",
    "        'explanation score':percent(performance_ltl/n),\n",
    "        'explanation score on ground truth':percent(performance_ltl_with_target/n),\n",
    "        'extraction time': end_time-start_time\n",
    "    }, ignore_index=True\n",
    ")\n",
    "print(result.to_string(index=False))\n",
    "result.to_csv('output/result.csv', header=False, index=False, mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read result\n",
    "# df=pd.read_csv(\"output/result.csv\",header=None)\n",
    "# df.columns=['target', \n",
    "#             'query', \n",
    "#             'explanation', \n",
    "#             'status', \n",
    "#             'rnn score', \n",
    "#             'explanation score', \n",
    "#             'explanation score on ground truth',\n",
    "#             'extraction time'\n",
    "#             ]\n",
    "# print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "entering block\nThis should never get printed because the line before timed out\nentering block\nThis should never get printed because the line before timed out\nprogram executed\n"
    }
   ],
   "source": [
    "import signal\n",
    "from contextlib import contextmanager\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timeout(time):\n",
    "    # Register a function to raise a TimeoutError on the signal.\n",
    "    signal.signal(signal.SIGALRM, raise_timeout)\n",
    "    # Schedule the signal to be sent after ``time``.\n",
    "    signal.alarm(time)\n",
    "\n",
    "    try:\n",
    "        yield\n",
    "    except TimeoutError:\n",
    "        pass\n",
    "    finally:\n",
    "        # Unregister the signal so it won't be triggered\n",
    "        # if the timeout is not reached.\n",
    "        signal.signal(signal.SIGALRM, signal.SIG_IGN)\n",
    "\n",
    "\n",
    "def raise_timeout(signum, frame):\n",
    "    raise TimeoutError\n",
    "\n",
    "import time\n",
    "\n",
    "def another_func():\n",
    "    print('entering block')\n",
    "def my_func():\n",
    "    # Add a timeout block.\n",
    "    with timeout(10):\n",
    "        i=0\n",
    "        while(i<2):\n",
    "            another_func()\n",
    "            i+=1\n",
    "            time.sleep(3)\n",
    "            print('This should never get printed because the line before timed out')\n",
    "    print(\"program executed\")\n",
    "my_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}