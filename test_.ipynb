{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from lstar_extraction.LSTM import LSTMNetwork\n",
    "# from GRU import GRUNetwork\n",
    "from lstar_extraction.RNNClassifier import RNNClassifier\n",
    "from lstar_extraction.Training_Functions import mixed_curriculum_train,make_train_set_for_target,make_test_set\n",
    "from lstar_extraction.Tomita_Grammars import tomita_1, tomita_2, tomita_3, tomita_4, tomita_5, tomita_6, tomita_7, tomita_8, tomita_9\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "made train set of size: 395 , of which positive examples: 30\n{'': True, 'r': False, 'R': False, 'l': False, 'L': False, 'LR': True, 'lr': True, 'Lr': False, 'rl': False, 'll': False, 'lL': False, 'lR': False, 'rL': False, 'LL': False, 'RL': False, 'Rr': False, 'Ll': False, 'rR': False, 'rr': False, 'Rl': False, 'RR': False, 'Rrr': False, 'lrL': False, 'RLr': False, 'LRL': False, 'rLr': False, 'llr': False, 'RlR': False, 'LrR': False, 'RrL': False, 'rRr': False, 'Lrl': False, 'llL': False, 'lRR': False, 'lLL': False, 'LlR': False, 'RLl': False, 'Lll': False, 'Rlr': False, 'lrR': False, 'rrr': False, 'lLRr': True, 'lrlr': True, 'LRLR': True, 'LRlr': True, 'LLRR': True, 'llrr': True, 'LlrR': True, 'lrLR': True, 'RLRL': False, 'rRrr': False, 'LRLr': False, 'rrlR': False, 'lLlL': False, 'lrRr': False, 'lrRR': False, 'LllR': False, 'rlrr': False, 'RRlR': False, 'RLLl': False, 'rLRl': False, 'rLrR': False, 'RrLr': False, 'rRLR': False, 'LrLR': False, 'RLLr': False, 'LrlR': False, 'lRrr': False, 'RrRr': False, 'RlRr': False, 'lRll': False, 'LLLL': False, 'llLr': False, 'LLll': False, 'RRrl': False, 'RRLR': False, 'rLLL': False, 'lllLR': False, 'llLrR': False, 'LlRRl': False, 'rRlrl': False, 'rllll': False, 'RLlll': False, 'LrLlR': False, 'LrlrR': False, 'RLllL': False, 'llRlR': False, 'rLRRl': False, 'rRrLr': False, 'lLrLR': False, 'lRlLr': False, 'LlRLR': False, 'RlRrR': False, 'rRLRr': False, 'rRLlL': False, 'rLRLL': False, 'LLRLl': False, 'lrLRLR': True, 'LlrLRR': True, 'LLlrRR': True, 'lrLLRR': True, 'LRllrr': True, 'LRLLRR': True, 'LLRRlr': True, 'LLRlrR': True, 'lrlrLR': True, 'lrLRlr': True, 'llrlrr': True, 'RRlLLl': False, 'LlrlRl': False, 'RLRLlR': False, 'rRrLrr': False, 'lrLlLL': False, 'LLLlLL': False, 'RRRlrR': False, 'LRLrrr': False, 'rrllrR': False, 'rrRRlr': False, 'rRLRlL': False, 'lRrLRr': False, 'lRRLll': False, 'RrRRRR': False, 'LrrlLR': False, 'lrRrrR': False, 'LrrRrL': False, 'RlllRL': False, 'lrllll': False, 'rLrRrR': False, 'rLrlrl': False, 'lrrRRL': False, 'lLLLll': False, 'LRRRrR': False, 'RlRLrl': False, 'rRLRrR': False, 'rRlLLl': False, 'lLRRLR': False, 'rlRlRR': False, 'LLrrRl': False, 'LrrlRL': False, 'rLRrrlL': False, 'RRLRRrr': False, 'RlRrlLL': False, 'rrLLRLl': False, 'RLrrrRR': False, 'rrRRlLL': False, 'RrRlLrr': False, 'rLLlrrl': False, 'rrllRRR': False, 'RRrrRRR': False, 'rrllRRr': False, 'rRlRlRR': False, 'lrrRllL': False, 'rRRrlLR': False, 'rrRrrRL': False, 'lRlrrlL': False, 'RrrLlrL': False, 'LrlrLLR': False, 'LRLllRl': False, 'RlrRrrl': False, 'lLRrllrr': True, 'lrllrrLR': True, 'lLRlrrlr': True, 'LRlrlrLR': True, 'llLlrRLR': False, 'LLlLRrrR': False, 'rRrLLlRL': False, 'rrLRLlLR': False, 'LRRRlLRR': False, 'rRLRlRRr': False, 'lLrLRrRR': False, 'rRLLLlLr': False, 'LllrLRLR': False, 'lRRLRRll': False, 'LLlRLRRR': False, 'LRLLRlrL': False, 'RrLRRlrR': False, 'rRLrrlRl': False, 'RLlLllRr': False, 'RLlRRLRl': False, 'rLrrLLLl': False, 'rRLLrLrl': False, 'LLrLRRRL': False, 'rRlLlLll': False, 'lRRLRRLl': False, 'rlLrRlLL': False, 'lLLLllll': False, 'LLrrRrlL': False, 'RLrlLlllR': False, 'RRLRLrRlr': False, 'rLRrLrLLR': False, 'LlllRllrl': False, 'LrllllRRr': False, 'LLrlRlrrL': False, 'RlrRLLrll': False, 'rLrLLrrrl': False, 'lRRRLRLlR': False, 'lrrlRLrll': False, 'lrLRrRlLr': False, 'LRRlRlrLL': False, 'LLllrRllr': False, 'rLrLrLlrL': False, 'RRRRLLRrL': False, 'RllRRRLlL': False, 'LLlRRlRrL': False, 'rllRrrLrl': False, 'rRrrlLLlR': False, 'LrllllLRl': False, 'llLlrRrrlr': True, 'LrRRlrLRRL': False, 'LLLRLllllR': False, 'lrllrrLRRL': False, 'lLrllllrLr': False, 'LLrRrRRlRR': False, 'LLRRLlrLLl': False, 'LRLrlLllrL': False, 'rrLLrLRRll': False, 'lRRrLLrrRL': False, 'lLlrRLrRlL': False, 'rlRLlLlRlL': False, 'rrRLRlRlrL': False, 'LllLlllRrl': False, 'LRlllrRlRl': False, 'RRLlRRrrRR': False, 'RRRlLRlRRl': False, 'LLRRrlrlLr': False, 'LLrLRRlrrl': False, 'RllrLlLRrR': False, 'lRlLlRRrLR': False, 'RRrrrRLlrR': False, 'rLrLLrrRLrr': False, 'rlLRrlLRrrR': False, 'rlRRrlrRlLL': False, 'LLrllLrrlLL': False, 'rLRlLrLllLr': False, 'LRLlLRlLRRr': False, 'RLLRLrlLLRR': False, 'lrRrLLLrRLl': False, 'rlLLllrrlLL': False, 'lLLLRLlLrll': False, 'llRlLLrllRL': False, 'LrLlRRrrLrr': False, 'RLRlRlLlRRl': False, 'rRrrrllRRLl': False, 'rlRRRLrLRLr': False, 'llLLllRRRrR': False, 'RrrRLRlllLL': False, 'lRrlrRLlllR': False, 'llLLlLrrlRL': False, 'rrlRrRLLRlr': False, 'lrLlrRLllrrR': True, 'lrLRlrLLlrRR': True, 'RRlLrRrlLlLr': False, 'llrlRrrrlrrL': False, 'LRRLlrrlLLLR': False, 'rrlrRlLRRRrl': False, 'RRlrRRrrRLrL': False, 'lrllRlrlRllL': False, 'rLlLlRRLLllR': False, 'lRRRLRRlrLRL': False, 'lRllRlrRrlrr': False, 'lrRLRRRlrRRl': False, 'rLLlRLrLllLR': False, 'LLRlLLrllrLr': False, 'RllllLlRllRl': False, 'LRlRllrrrrLL': False, 'RLlLlLrLLlll': False, 'rrLlRrRrllRL': False, 'lLRlrrrLLLLL': False, 'rrLrrLRRlRll': False, 'rlrRRRlRLLLr': False, 'lRRlLRllllLr': False, 'RLlrLrrrrrlr': False, 'LLlRrrLLlLRL': False, 'RllllRRRLlrRr': False, 'rrLrlLRLLLRrL': False, 'LrRrLlRRLrrRL': False, 'LLlrRlRLLLLLR': False, 'LrLRrlRlrLRLL': False, 'RLlrlRRlLrLLR': False, 'RLLrLllrrlRrR': False, 'rLLllRRLrRRlL': False, 'rrlRRLrRrrRLL': False, 'RlrLlRlrlLlLL': False, 'RrrRLRlRLlrLl': False, 'LRrLrrLRLrLlR': False, 'rlRLLRlLrRlRR': False, 'RrRlrllrllrLl': False, 'rRRlrrLrrLlrL': False, 'LrrrlRRrRRrrl': False, 'LrrrlrrLlLrlR': False, 'LlRRRlLRRllrR': False, 'rrlRrlrLLRlRR': False, 'rlRlRrrLlLRRL': False, 'LLLlrLLRLRRRRR': True, 'rllrlRrrlLRLLr': False, 'lRRlrrrRlrrLRr': False, 'rlLlRrRRlrRrRr': False, 'rLLlLrlRllLlLr': False, 'lRlrLRrrrlLRRl': False, 'LLRrlrLllLLrrr': False, 'rrRrlRLLlRLrLr': False, 'rllrrrRRLrrlRR': False, 'rrrLLlrlRlrlrL': False, 'lLrRrlLRRRrLrr': False, 'LrlLrRllRRrlLR': False, 'rLLLlllLLlRRRl': False, 'rrRlLRRlrRlLLr': False, 'rLrlRlrlrLrrrL': False, 'rRlRLLRllLrrLr': False, 'LrrrrrLLllLLLr': False, 'lLlLlLLrlLrRRl': False, 'lRlrLLrrRrlRlL': False, 'lrrrrlrrlrrRLl': False, 'rRrrlLRrLrRLrr': False, 'lLRlrrLlLRrlRL': False, 'RlRLLRLRrrrlRRL': False, 'RrLrrrlllLRlrRr': False, 'lLllLlrRlrRrLrl': False, 'lRllrRRllrlllLl': False, 'RrlllrllLRLRrlL': False, 'llRlRRrLRrRlRrr': False, 'RlRRRlrRRlLRrLl': False, 'LLrlrlrLrllLlrL': False, 'lRlRlLrlLRRrlrr': False, 'LlrRllrRLrLrlLR': False, 'RlLLrLrrRrrRlRL': False, 'RlrRrRRLlrRRLlR': False, 'lllLRlLRrlLrrrR': False, 'RRlRrllrRLLrLLR': False, 'lRrlRRrlRLLlrLr': False, 'llRLRLLRRllRrlr': False, 'rRlRLrlLRrlLRRl': False, 'lrLlRllRlRrlLrL': False, 'RLrrLrlLRlLlRll': False, 'lRLRLrrLlrRlrlr': False, 'RrlLrLRRRRRRrRlLrLrr': False, 'lRLlrRRlLLRLrllRlLLr': False, 'rRlRrRlrlLLLRLLllLrR': False, 'lLlrlLrrrRRrlRrRrlLr': False, 'LRlLrLrrLlllllrLRrlr': False, 'LLllRllrLrlLLrLlrlRL': False, 'LlRlLlRrLrRRLRRlrrll': False, 'LlLlRRRlrlRlLLlllLrL': False, 'rrrlrRRRrlrLRllLRRll': False, 'lrlRrRLRlRRlRrLLLRRR': False, 'rLrRRRrRlrlRrRlLLrrl': False, 'RlRRRrrrLrRLLrrllrRR': False, 'lRrLrLrLllRrrrrLlrLr': False, 'LRrRlLlrLrrrLLRllLrl': False, 'rrrrRLrRlRLLLrlLLrRr': False, 'rlrrRllRlrlrRlRRLLrR': False, 'RrlLRRrLlLRRRRrrrrlL': False, 'lrlrlRrLlRrLLLLRlrRr': False, 'lLrRlLlLlLlRlLRLRLRL': False, 'rrlLRrLLLrrrRLLrLrrL': False, 'LRLlLRrlrLLlLrLRllrLrLrRL': False, 'RlrLllLrlRLRRRLRLLLrRrLrL': False, 'LLrLlLllrlRRLllLRLrRLrRlL': False, 'LlRRLlLlLLrLlRRrllRlRlrRL': False, 'rLrRRllrllrrrLRlrlLRLrRrR': False, 'rLLLrlLllRlrRLrRRlrLrLLLR': False, 'lRLRlLRLRlRlRRLlLlRlRRrlR': False, 'RRLLLLrrLLlrLlLlLLlrLRLRl': False, 'rrrlLLLRLLLRlrlRLLlrLLRRl': False, 'LLLlLllLrLrLrLRLlRLrLLrLl': False, 'lRrllRRLLlrRlLllllrllrLrR': False, 'rLRRlRLLRrrlLRlRrrRLLlRrr': False, 'RrLlRrLlrLLlLLLRLRRRLrlrL': False, 'lrrLLRLRRRlLRLRlrRRLRrrlR': False, 'LlrRRrRLRrrrLrRLlRRlllLLR': False, 'RrLRlRRRRllLRlrLrRLRLLlLr': False, 'RrlrRrllRLLRrLRLRLrlrLLrl': False, 'llLRlllrLlRllRlLRLRrllrrl': False, 'RlLLRRlLRlrlrlrrrlrrRRlLl': False, 'llRLRLlRrlRLrLRllrlRRlllL': False, 'LLlLrrrlLLLLrlLlrrrLrlRRLlrLLL': False, 'RrLlLRLlrrLRrlRrllrlLRLrRRlRLR': False, 'rLllRRlLLlrlLlrrRLLLLlLLllRlLR': False, 'LrllLRlLLRLLrLlrrrLRrrlrlRRLrR': False, 'lLLRRrrRrrrLlrLlLrrRRRlLrrLrRL': False, 'LrRRLlLrRLrlRrLlrLLRlrrrrrRLlR': False, 'rRRrlrLRlLRRRllRlLLRlrlLLLrrRR': False, 'RLRrlLrLLRRRrRRrLrlLRRRLLrrRLl': False, 'rrLRlrrrLLllLLRRrlRRLlrrLlrRRR': False, 'RRlLRRLRRllRlrRRrRLlrLlrLlRLRL': False, 'lRrLrrLLLlRrLRllllLlLllllrrLlR': False, 'RrrLlLRRlRllrlLlRlLrrllRlrrlrl': False, 'llrlLrrrlrrLRlRrLRrlLLLLllllrL': False, 'RLLrLRLrLLlLRlRRlrRRLlLLlRLllL': False, 'llRllllLLLLlRRlRLrLRRrLlRRLRLL': False, 'lrRrrlrlRlRRLrrRrlLRRLLlLLRrRL': False, 'lRLrRlrrlLLlRRRlrLrLrrllLLLLLR': False, 'llrrlRLllLLRrLrrlLRLlLLRRLRLLR': False, 'RlllrrlrrrRRRrlRRLrRRRrrLrLLlL': False, 'LrrlLrlLlllRlLLlrRlRLlLLLLRRLR': False}\n"
    }
   ],
   "source": [
    "# make training set\n",
    "target = tomita_9\n",
    "\n",
    "alphabet = \"lrab\"\n",
    "\n",
    "# alphabet = \"abcd\"\n",
    "train_set = make_train_set_for_target(target,alphabet)\n",
    "\n",
    "# define rnn\n",
    "rnn = RNNClassifier(alphabet,num_layers=1,hidden_dim=10,RNNClass = LSTMNetwork)\n",
    "\n",
    "\n",
    "print(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "current average loss is:  0.19445215473572414\ncurrent average loss is:  0.13974708408117295\ncurrent average loss is:  0.12972278172771137\ncurrent average loss is:  0.11243788803617158\ncurrent average loss is:  0.085654362787803\ncurrent average loss is:  0.06849878045577037\ncurrent average loss is:  0.06289611043809336\ncurrent average loss is:  0.05947892394246934\ncurrent average loss is:  0.05629581016830251\ncurrent average loss is:  0.05275359817698032\ncurrent average loss is:  0.06089839873214562\ncurrent average loss is:  0.044926479781667396\ncurrent average loss is:  0.0389688050126036\ncurrent average loss is:  0.04239143536581347\ncurrent average loss is:  0.03111137185245752\ncurrent average loss is:  0.028144454956054686\ncurrent average loss is:  0.0264485274689107\ncurrent average loss is:  0.02482417867153506\ncurrent average loss is:  0.023392906671837917\ncurrent average loss is:  0.022124910958205596\ncurrent average loss is:  0.02933416626416146\ncurrent average loss is:  0.018665724659028153\ncurrent average loss is:  0.01641004223066072\ncurrent average loss is:  0.015100240433821457\ncurrent average loss is:  0.012906824334058908\ncurrent average loss is:  0.01155038664612589\ncurrent average loss is:  0.010377711284009716\ncurrent average loss is:  0.009297918367989455\ncurrent average loss is:  0.008312203008917314\ncurrent average loss is:  0.007339588599868967\nclassification loss on last batch was: 0.007339588599868967\n"
    }
   ],
   "source": [
    "# train the model\n",
    "mixed_curriculum_train(rnn,train_set,stop_threshold = 0.0005)\n",
    "rnn.renew()  \n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "made test set of size: 175\n"
    }
   ],
   "source": [
    " # generate_test_set\n",
    "\n",
    "\n",
    "test_set=make_test_set(alphabet)\n",
    "\n",
    "from test_xRNN import Traces\n",
    "\n",
    "\n",
    "\n",
    "traces=Traces(rnn, alphabet)\n",
    "traces.label_from_network(test_set)\n",
    "traces.write_in_file()\n",
    "\n",
    "# starting examples\n",
    "# all_words = sorted(list(train_set.keys()),key=lambda x:len(x))\n",
    "# pos = next((w for w in all_words if rnn.classify_word(w)==True),None)\n",
    "# neg = next((w for w in all_words if rnn.classify_word(w)==False),None)\n",
    "# starting_examples = [w for w in [pos,neg] if not None == w]\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "provided counterexamples are: None\n\n\n\nstart formula depth: 1\nIllegal character 'L' in the input formula\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Syntax error in input! LexToken(RPAR,')',1,4)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-c85611212c72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdfa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mltl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_split_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstarting_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# print(dfa)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/explainableRNN/scripts/lstar_extraction/Extraction.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(rnn, alphabet, traces, time_limit, initial_split_depth, starting_examples)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mrun_lstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguided_teacher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphabet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#you can press the stop button in the notebook to stop the extraction any time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lstar extraction terminated by user\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/explainableRNN/scripts/lstar_extraction/Lstar.py\u001b[0m in \u001b[0;36mrun_lstar\u001b[0;34m(teacher, time_limit, alphabet, traces)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# dfa = DFA.DFA(obs_table=table)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_ltlf_and_dfa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mdfa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"obs table refinement took \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/explainableRNN/scripts/test_xRNN.py\u001b[0m in \u001b[0;36mlearn_ltlf_and_dfa\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mltl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"false\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDFA_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_ltl2dfa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mltl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"learned LTL formula:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mltl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/explainableRNN/scripts/test_ltl2dfa.py\u001b[0m in \u001b[0;36mtranslate_ltl2dfa\u001b[0;34m(alphabet, formula)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdeclare_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# True if you want to compute DECLARE assumption for the formula\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateMonafile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeclare_flag\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# it creates automa.mona file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/explainableRNN/scripts/ltlf2dfa/Translator.py\u001b[0m in \u001b[0;36mformula_parser\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_alphabet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed_formula\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula_to_be_parsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ooops! You typed a formula with mixed past/future operators'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/explainableRNN/scripts/ltlf2dfa/Parser.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, s, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mp_formula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ply/yacc.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, input, lexer, debug, tracking, tokenfunc)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseopt_notrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ply/yacc.py\u001b[0m in \u001b[0;36mparseopt_notrack\u001b[0;34m(self, input, lexer, debug, tracking, tokenfunc)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                             \u001b[0merrtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m                         \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_errorfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m                             \u001b[0;31m# User must have done some kind of panic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ply/yacc.py\u001b[0m in \u001b[0;36mcall_errorfunc\u001b[0;34m(errorfunc, token, parser)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0m_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0m_restart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrorfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0m_errok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_restart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/explainableRNN/scripts/ltlf2dfa/Parser.py\u001b[0m in \u001b[0;36mp_error\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mp_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Syntax error in input! %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Syntax error in input! LexToken(RPAR,')',1,4)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# rnn.renew() \n",
    "\n",
    "# extract DFA from RNN\n",
    "from lstar_extraction.Extraction import extract\n",
    "\n",
    "\n",
    "dfa, ltl = extract(rnn,alphabet,traces, time_limit = 50,initial_split_depth = 10,starting_examples=None)\n",
    "\n",
    "# print(dfa)\n",
    "print(\"\\n\\nfinal LTL formula:\", ltl)\n",
    "# dfa.draw_nicely(maximum=30) #max size willing to draw\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}