{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from lstar_extraction.LSTM import LSTMNetwork\n",
    "# from GRU import GRUNetwork\n",
    "from lstar_extraction.RNNClassifier import RNNClassifier\n",
    "from lstar_extraction.Training_Functions import mixed_curriculum_train,make_train_set_for_target,make_test_set\n",
    "from lstar_extraction.Tomita_Grammars import tomita_1, tomita_2, tomita_3, tomita_4, tomita_5, tomita_6, tomita_7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "made train set of size: 2766 , of which positive examples: 1330\nmade train set of size: 521 , of which positive examples: 424\ncurrent average loss is:  0.0293452719864608\ncurrent average loss is:  0.008365188865853405\ncurrent average loss is:  0.00427742039276011\ncurrent average loss is:  0.0029724633071088686\ncurrent average loss is:  0.002245852260212241\ncurrent average loss is:  0.001995311588792563\ncurrent average loss is:  0.001752546561199049\ncurrent average loss is:  0.001564768934890542\ncurrent average loss is:  0.0014119950228597747\ncurrent average loss is:  0.0012832703837506374\ncurrent average loss is:  0.0007247093587163059\nclassification loss on last batch was: 0.000495032183836749\n"
    }
   ],
   "source": [
    "# make training set\n",
    "target = tomita_3\n",
    "alphabet = \"01\"\n",
    "train_set = make_train_set_for_target(target,alphabet)\n",
    "\n",
    "\n",
    "# define the manual labelling of words\n",
    "def target(w):\n",
    "    if(\"aa\" in w):\n",
    "        return True\n",
    "    return False\n",
    "alphabet = \"abc\"\n",
    "train_set = make_train_set_for_target(target,alphabet)\n",
    "\n",
    "# define rnn\n",
    "rnn = RNNClassifier(alphabet,num_layers=1,hidden_dim=10,RNNClass = LSTMNetwork)\n",
    "\n",
    "# train the model\n",
    "mixed_curriculum_train(rnn,train_set,stop_threshold = 0.0005)\n",
    "rnn.renew()  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "made test set of size: 175\n"
    }
   ],
   "source": [
    "# generate_test_set\n",
    "test_set=make_test_set(alphabet)\n",
    "\n",
    "from test_xRNN import Traces\n",
    "\n",
    "\n",
    "\n",
    "traces=Traces(rnn, alphabet)\n",
    "traces.label_from_network(test_set)\n",
    "traces.write_in_file()\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# starting examples\n",
    "all_words = sorted(list(train_set.keys()),key=lambda x:len(x))\n",
    "pos = next((w for w in all_words if rnn.classify_word(w)==True),None)\n",
    "neg = next((w for w in all_words if rnn.classify_word(w)==False),None)\n",
    "starting_examples = [w for w in [pos,neg] if not None == w]\n",
    "\n",
    "# rnn.renew()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "provided counterexamples are: None\n\n\n\nlearned LTL formula: (a | b)\nobs table refinement took 0.198\nguided starting equivalence query for DFA of size 3\nsplit wasn't perfect: gotta start over\nFound counterexample, that is rejected by the dfa\nreturning counterexample of length 2:\t\tca, this counterexample is accepted by the given RNN.\nequivalence checking took: 0.04410699999999679\n\n\n\nlearned LTL formula: (b | (F a))\nobs table refinement took 0.469\nguided starting equivalence query for DFA of size 3\nFound counterexample, that is rejected by the dfa\nreturning counterexample of length 2:\t\tcb, this counterexample is accepted by the given RNN.\nequivalence checking took: 0.0028650000000141063\n\n\n\nlearned LTL formula: (F (a | b))\nobs table refinement took 0.54\nguided starting equivalence query for DFA of size 3\nlstar successful: unrolling seems equivalent to proposed automaton\nequivalence checking took: 0.0033709999999871343\noverall guided extraction time took: 1.2603249999999946\ngenerated counterexamples were: (format: (counterexample, counterexample generation time))\n('ca', 0.04410699999999679)\n('cb', 0.0028650000000141063)\n\n\nfinal LTL formula: (F (a | b))\n"
    }
   ],
   "source": [
    "# extract DFA from RNN\n",
    "from lstar_extraction.Extraction import extract\n",
    "\n",
    "\n",
    "dfa, ltl = extract(rnn,alphabet,traces, time_limit = 50,initial_split_depth = 10,starting_examples=None)\n",
    "\n",
    "# print(dfa)\n",
    "print(\"\\n\\nfinal LTL formula:\", ltl)\n",
    "# dfa.draw_nicely(maximum=30) #max size willing to draw\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}