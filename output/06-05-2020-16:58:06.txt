made train set of size: 7660 , of which positive examples: 3656
The dy.parameter(...) call is now DEPRECATED.
        There is no longer need to explicitly add parameters to the computation graph.
        Any used parameter will be added automatically.
current average loss is:  0.006100976211795168
classification loss on last batch was: 3.583452139959592e-05
testing on train set, i.e. test set is train set
test set size: 9245
rnn score against target on test set:                              9245 (100.0)
query: false


positive traces---> 
[]


negative traces---> 
[]



learned LTL formula: true
Learning took:  0.20190978050231934  s
EQ test took  0.0010027885437011719  s
new counterexample:   should be rejected by implementation


positive traces---> 
[]


negative traces---> 
['']



0  iteration complete



learned LTL formula: false
Learning took:  0.19795584678649902  s
EQ test took  0.634946346282959  s


epsilon= 0.05 delta= 0.05 max_trace_length= 20
query: false
final ltl:  false

Time taken: 1.0411369800567627
target  query explanation status  rnn score  explanation score  explanation score on ground truth  extraction time
email match  false       false   True      100.0                0.0                                0.0         1.041137
query: true


positive traces---> 
[]


negative traces---> 
[]



learned LTL formula: true
Learning took:  0.1965627670288086  s
EQ test took  0.0010805130004882812  s
new counterexample:   should be rejected by implementation


positive traces---> 
[]


negative traces---> 
['']



0  iteration complete



learned LTL formula: false
Learning took:  0.19713401794433594  s
EQ test took  0.6170749664306641  s
new counterexample: rard  should be accepted by implementation


positive traces---> 
['rard']


negative traces---> 
['']



1  iteration complete



start formula depth: 1
learned LTL formula: r
Learning took:  0.3870820999145508  s
EQ test took  0.29058194160461426  s
new counterexample: r  should be rejected by implementation


positive traces---> 
['rard']


negative traces---> 
['', 'r']



2  iteration complete



start formula depth: 1
learned LTL formula: (F d)
Learning took:  0.8113064765930176  s
No positive counterexample found
EQ test took  0.5133450031280518  s
new counterexample: d  should be rejected by implementation


positive traces---> 
['rard']


negative traces---> 
['', 'r', 'd']



3  iteration complete



start formula depth: 2
learned LTL formula: (F a)
Learning took:  0.8169565200805664  s
EQ test took  0.3126533031463623  s
new counterexample: prqrpd  should be accepted by implementation


positive traces---> 
['rard', 'prqrpd']


negative traces---> 
['', 'r', 'd']



4  iteration complete



start formula depth: 2
learned LTL formula: (r U (X r))
Learning took:  2.6178627014160156  s
EQ test took  0.4246406555175781  s
new counterexample: qr  should be rejected by implementation


positive traces---> 
['rard', 'prqrpd']


negative traces---> 
['', 'r', 'd', 'qr']



5  iteration complete



start formula depth: 3
learned LTL formula: (X (F d))
Learning took:  2.3535163402557373  s
No positive counterexample found
EQ test took  0.4467628002166748  s
new counterexample: pd  should be rejected by implementation


positive traces---> 
['rard', 'prqrpd']


negative traces---> 
['', 'r', 'd', 'qr', 'pd']



6  iteration complete



start formula depth: 3
learned LTL formula: (F (X (X d)))
Learning took:  6.737375497817993  s
No positive counterexample found
EQ test took  0.5396413803100586  s
new counterexample: mpd  should be rejected by implementation


positive traces---> 
['rard', 'prqrpd']


negative traces---> 
['', 'r', 'd', 'qr', 'pd', 'mpd']



7  iteration complete



start formula depth: 4
learned LTL formula: (X (X (F r)))
Learning took:  5.819583177566528  s
EQ test took  0.3818345069885254  s
new counterexample: qqmad  should be accepted by implementation


positive traces---> 
['rard', 'prqrpd', 'qqmad']


negative traces---> 
['', 'r', 'd', 'qr', 'pd', 'mpd']



8  iteration complete



start formula depth: 4
learned LTL formula: (X (X (~ d)))
Learning took:  6.875589370727539  s
EQ test took  0.38164639472961426  s
new counterexample: arm  should be rejected by implementation


positive traces---> 
['rard', 'prqrpd', 'qqmad']


negative traces---> 
['', 'r', 'd', 'qr', 'pd', 'mpd', 'arm']



9  iteration complete



start formula depth: 4
learned LTL formula: (X (a | (F q)))
Learning took:  20.142427921295166  s
No positive counterexample found
EQ test took  0.5136075019836426  s
new counterexample: pa  should be rejected by implementation


positive traces---> 
['rard', 'prqrpd', 'qqmad']


negative traces---> 
['', 'r', 'd', 'qr', 'pd', 'mpd', 'arm', 'pa']



10  iteration complete



start formula depth: 5
learned LTL formula: (X (X (X (p -> p))))
Learning took:  14.365085124969482  s
No positive counterexample found
EQ test took  0.33013200759887695  s
new counterexample: qdmr  should be rejected by implementation


positive traces---> 
['rard', 'prqrpd', 'qqmad']


negative traces---> 
['', 'r', 'd', 'qr', 'pd', 'mpd', 'arm', 'pa', 'qdmr']



11  iteration complete



start formula depth: 5
learned LTL formula: (X (X (X (F d))))
Learning took:  15.76366901397705  s
No positive counterexample found
EQ test took  0.8063974380493164  s
new counterexample: drpd  should be rejected by implementation


positive traces---> 
['rard', 'prqrpd', 'qqmad']


negative traces---> 
['', 'r', 'd', 'qr', 'pd', 'mpd', 'arm', 'pa', 'qdmr', 'drpd']



12  iteration complete



start formula depth: 5
learned LTL formula: (X (r U (q | (X r))))
Learning took:  48.508185386657715  s
EQ test took  0.5736644268035889  s
new counterexample: qmad  should be accepted by implementation


positive traces---> 
['rard', 'prqrpd', 'qqmad', 'qmad']


negative traces---> 
['', 'r', 'd', 'qr', 'pd', 'mpd', 'arm', 'pa', 'qdmr', 'drpd']



13  iteration complete



start formula depth: 6
learned LTL formula: (~ ((X (X d)) U ((F (X (X d))) -> d)))
Learning took:  251.6809720993042  s
EQ test took  1.0651204586029053  s
new counterexample: anpd  should be rejected by implementation


positive traces---> 
['rard', 'prqrpd', 'qqmad', 'qmad']


negative traces---> 
['', 'r', 'd', 'qr', 'pd', 'mpd', 'arm', 'pa', 'qdmr', 'drpd', 'anpd']



14  iteration complete





epsilon= 0.05 delta= 0.05 max_trace_length= 20
query: true
final ltl:  (~ ((X (X d)) U ((F (X (X d))) -> d)))
incomplete formula

Time taken: 401.04671812057495
target query                             explanation status  rnn score  explanation score  explanation score on ground truth  extraction time
email match  true  (~ ((X (X d)) U ((F (X (X d))) -> d)))  False      100.0                0.0                                0.0       401.046718
query: (m|n)


positive traces---> 
[]


negative traces---> 
[]



learned LTL formula: true
Learning took:  0.25623226165771484  s
EQ test took  0.0009236335754394531  s
new counterexample:   should be rejected by implementation


positive traces---> 
[]


negative traces---> 
['']



0  iteration complete



learned LTL formula: false
Learning took:  0.2067427635192871  s
EQ test took  0.6313798427581787  s


epsilon= 0.05 delta= 0.05 max_trace_length= 20
query: (m|n)
final ltl:  false

Time taken: 1.1004974842071533
target  query explanation status  rnn score  explanation score  explanation score on ground truth  extraction time
email match  (m|n)       false   True      100.0                0.0                                0.0         1.100497
query: ~F(a)


positive traces---> 
[]


negative traces---> 
[]



learned LTL formula: true
Learning took:  0.2922079563140869  s
EQ test took  0.0011355876922607422  s
new counterexample:   should be rejected by implementation


positive traces---> 
[]


negative traces---> 
['']



0  iteration complete



learned LTL formula: false
Learning took:  0.26231861114501953  s
EQ test took  0.671008825302124  s


epsilon= 0.05 delta= 0.05 max_trace_length= 20
query: ~F(a)
final ltl:  false

Time taken: 1.231891393661499
target  query explanation status  rnn score  explanation score  explanation score on ground truth  extraction time
email match  ~F(a)       false   True      100.0                0.0                                0.0         1.231891
query: ~F(d)


positive traces---> 
[]


negative traces---> 
[]



learned LTL formula: true
Learning took:  0.3603997230529785  s
EQ test took  0.0011363029479980469  s
new counterexample:   should be rejected by implementation


positive traces---> 
[]


negative traces---> 
['']



0  iteration complete



learned LTL formula: false
Learning took:  0.21444463729858398  s
EQ test took  0.6350476741790771  s


epsilon= 0.05 delta= 0.05 max_trace_length= 20
query: ~F(d)
final ltl:  false

Time taken: 1.216352939605713
target  query explanation status  rnn score  explanation score  explanation score on ground truth  extraction time
email match  ~F(d)       false   True      100.0                0.0                                0.0         1.216353
query: F(a & X(m|n))


positive traces---> 
[]


negative traces---> 
[]



learned LTL formula: true
Learning took:  0.22004485130310059  s
EQ test took  0.0009307861328125  s
new counterexample:   should be rejected by implementation


positive traces---> 
[]


negative traces---> 
['']



0  iteration complete



learned LTL formula: false
Learning took:  0.2708923816680908  s
EQ test took  0.6316516399383545  s


epsilon= 0.05 delta= 0.05 max_trace_length= 20
query: F(a & X(m|n))
final ltl:  false

Time taken: 1.1289126873016357
target          query explanation status  rnn score  explanation score  explanation score on ground truth  extraction time
email match  F(a & X(m|n))       false   True      100.0                0.0                                0.0         1.128913
query: F((m|n) & X(d))


positive traces---> 
[]


negative traces---> 
[]



learned LTL formula: true
Learning took:  0.2256457805633545  s
EQ test took  0.0009291172027587891  s
new counterexample:   should be rejected by implementation


positive traces---> 
[]


negative traces---> 
['']



0  iteration complete



learned LTL formula: false
Learning took:  0.22495317459106445  s
EQ test took  0.6331155300140381  s


epsilon= 0.05 delta= 0.05 max_trace_length= 20
query: F((m|n) & X(d))
final ltl:  false

Time taken: 1.089949607849121
target            query explanation status  rnn score  explanation score  explanation score on ground truth  extraction time
email match  F((m|n) & X(d))       false   True      100.0                0.0                                0.0          1.08995
query: G(m|n)


positive traces---> 
[]


negative traces---> 
[]



learned LTL formula: true
Learning took:  0.22706174850463867  s
EQ test took  0.0009336471557617188  s
new counterexample:   should be rejected by implementation


positive traces---> 
[]


negative traces---> 
['']



0  iteration complete



learned LTL formula: false
Learning took:  0.25025010108947754  s
EQ test took  0.6720390319824219  s


epsilon= 0.05 delta= 0.05 max_trace_length= 20
query: G(m|n)
final ltl:  false

Time taken: 1.1556048393249512
target   query explanation status  rnn score  explanation score  explanation score on ground truth  extraction time
email match  G(m|n)       false   True      100.0                0.0                                0.0         1.155605
query: F(m|n)->((p|q|r)U(m|n))


positive traces---> 
[]


negative traces---> 
[]



learned LTL formula: true
Learning took:  0.2320880889892578  s
EQ test took  0.0011255741119384766  s
new counterexample:   should be rejected by implementation


positive traces---> 
[]


negative traces---> 
['']



0  iteration complete



learned LTL formula: false
Learning took:  0.29654479026794434  s
EQ test took  0.6290037631988525  s
new counterexample: raqd  should be accepted by implementation


positive traces---> 
['raqd']


negative traces---> 
['']



1  iteration complete



start formula depth: 1
learned LTL formula: r
Learning took:  0.4750499725341797  s
EQ test took  0.4010603427886963  s
new counterexample: r  should be rejected by implementation


positive traces---> 
['raqd']


negative traces---> 
['', 'r']



2  iteration complete



start formula depth: 1
learned LTL formula: (X a)
Learning took:  0.8326160907745361  s
EQ test took  0.8614087104797363  s
new counterexample: rpard  should be accepted by implementation


positive traces---> 
['raqd', 'rpard']


negative traces---> 
['', 'r']



3  iteration complete



start formula depth: 2
learned LTL formula: (F a)
Learning took:  0.942929744720459  s
EQ test took  0.3251798152923584  s
new counterexample: a  should be rejected by implementation


positive traces---> 
['raqd', 'rpard']


negative traces---> 
['', 'r', 'a']



4  iteration complete



start formula depth: 2
learned LTL formula: (F d)
Learning took:  1.028538703918457  s
No positive counterexample found
EQ test took  0.3561379909515381  s
new counterexample: d  should be rejected by implementation


positive traces---> 
['raqd', 'rpard']


negative traces---> 
['', 'r', 'a', 'd']



5  iteration complete



start formula depth: 2
learned LTL formula: (X (~ r))
Learning took:  2.7083334922790527  s
EQ test took  0.27759313583374023  s
new counterexample: rrmnqpprqnrppd  should be accepted by implementation


positive traces---> 
['raqd', 'rpard', 'rrmnqpprqnrppd']


negative traces---> 
['', 'r', 'a', 'd']



6  iteration complete



start formula depth: 3
learned LTL formula: (X (n -> n))
Learning took:  4.421164274215698  s
EQ test took  0.12931060791015625  s
new counterexample: ad  should be rejected by implementation


positive traces---> 
['raqd', 'rpard', 'rrmnqpprqnrppd']


negative traces---> 
['', 'r', 'a', 'd', 'ad']



7  iteration complete



start formula depth: 3
learned LTL formula: (X (~ d))
Learning took:  4.803603172302246  s
No positive counterexample found
EQ test took  0.3404552936553955  s
new counterexample: pn  should be rejected by implementation


positive traces---> 
['raqd', 'rpard', 'rrmnqpprqnrppd']


negative traces---> 
['', 'r', 'a', 'd', 'ad', 'pn']



8  iteration complete



start formula depth: 3
learned LTL formula: ((r U (~ r)) & r)
Learning took:  14.70353102684021  s
EQ test took  0.26076722145080566  s
new counterexample: qapd  should be accepted by implementation


positive traces---> 
['raqd', 'rpard', 'rrmnqpprqnrppd', 'qapd']


negative traces---> 
['', 'r', 'a', 'd', 'ad', 'pn']



9  iteration complete



start formula depth: 4
learned LTL formula: (F (X (X d)))
Learning took:  11.317409038543701  s
EQ test took  0.6009538173675537  s
new counterexample: rqd  should be rejected by implementation


positive traces---> 
['raqd', 'rpard', 'rrmnqpprqnrppd', 'qapd']


negative traces---> 
['', 'r', 'a', 'd', 'ad', 'pn', 'rqd']



10  iteration complete



start formula depth: 4
learned LTL formula: (X (X (~ d)))
Learning took:  12.294275522232056  s
No positive counterexample found
EQ test took  0.43724751472473145  s
new counterexample: mqp  should be rejected by implementation


positive traces---> 
['raqd', 'rpard', 'rrmnqpprqnrppd', 'qapd']


negative traces---> 
['', 'r', 'a', 'd', 'ad', 'pn', 'rqd', 'mqp']



11  iteration complete



start formula depth: 4
learned LTL formula: (r U (X (r | a)))
Learning took:  37.07975769042969  s
EQ test took  1.1698179244995117  s
new counterexample: pmad  should be accepted by implementation


positive traces---> 
['raqd', 'rpard', 'rrmnqpprqnrppd', 'qapd', 'pmad']


negative traces---> 
['', 'r', 'a', 'd', 'ad', 'pn', 'rqd', 'mqp']



12  iteration complete



start formula depth: 5
learned LTL formula: (F (X (m | a)))
Learning took:  26.167502403259277  s
EQ test took  0.32469749450683594  s
new counterexample: pa  should be rejected by implementation


positive traces---> 
['raqd', 'rpard', 'rrmnqpprqnrppd', 'qapd', 'pmad']


negative traces---> 
['', 'r', 'a', 'd', 'ad', 'pn', 'rqd', 'mqp', 'pa']



13  iteration complete



start formula depth: 5
learned LTL formula: (X (X (X (q -> q))))
Learning took:  26.43734073638916  s
No positive counterexample found
EQ test took  0.3939366340637207  s
new counterexample: aapm  should be rejected by implementation


positive traces---> 
['raqd', 'rpard', 'rrmnqpprqnrppd', 'qapd', 'pmad']


negative traces---> 
['', 'r', 'a', 'd', 'ad', 'pn', 'rqd', 'mqp', 'pa', 'aapm']



14  iteration complete



start formula depth: 5
learned LTL formula: (X (X (X (F d))))
Learning took:  28.118377447128296  s
No positive counterexample found
EQ test took  1.0321929454803467  s
new counterexample: aard  should be rejected by implementation


positive traces---> 
['raqd', 'rpard', 'rrmnqpprqnrppd', 'qapd', 'pmad']


negative traces---> 
['', 'r', 'a', 'd', 'ad', 'pn', 'rqd', 'mqp', 'pa', 'aapm', 'aard']



15  iteration complete



start formula depth: 5
learned LTL formula: ((X (X (X (~ a)))) & (~ a))
Learning took:  154.78848910331726  s
EQ test took  0.5338029861450195  s
new counterexample: qnnapd  should be accepted by implementation


positive traces---> 
['raqd', 'rpard', 'rrmnqpprqnrppd', 'qapd', 'pmad', 'qnnapd']


negative traces---> 
['', 'r', 'a', 'd', 'ad', 'pn', 'rqd', 'mqp', 'pa', 'aapm', 'aard']



16  iteration complete





epsilon= 0.05 delta= 0.05 max_trace_length= 20
query: F(m|n)->((p|q|r)U(m|n))
final ltl:  ((X (X (X (~ a)))) & (~ a))
incomplete formula

Time taken: 401.09865045547485
target                    query                  explanation status  rnn score  explanation score  explanation score on ground truth  extraction time
email match  F(m|n)->((p|q|r)U(m|n))  ((X (X (X (~ a)))) & (~ a))  False      100.0                0.0                                0.0        401.09865
query: ~(F(m|n)->((p|q|r)U(m|n)))


positive traces---> 
[]


negative traces---> 
[]



learned LTL formula: true
Learning took:  0.2886486053466797  s
EQ test took  0.0009758472442626953  s
new counterexample:   should be rejected by implementation


positive traces---> 
[]


negative traces---> 
['']



0  iteration complete



learned LTL formula: false
Learning took:  0.33997416496276855  s
EQ test took  0.8599410057067871  s


epsilon= 0.05 delta= 0.05 max_trace_length= 20
query: ~(F(m|n)->((p|q|r)U(m|n)))
final ltl:  false

Time taken: 1.495030164718628
target                       query explanation status  rnn score  explanation score  explanation score on ground truth  extraction time
email match  ~(F(m|n)->((p|q|r)U(m|n)))       false   True      100.0                0.0                                0.0          1.49503
query: (F(m|n))&((p|q|r)U(m|n))


positive traces---> 
[]


negative traces---> 
[]



learned LTL formula: true
Learning took:  0.31410694122314453  s
EQ test took  0.0009291172027587891  s
new counterexample:   should be rejected by implementation


positive traces---> 
[]


negative traces---> 
['']



0  iteration complete



learned LTL formula: false
Learning took:  0.2694666385650635  s
EQ test took  0.7956564426422119  s
new counterexample: qqmrnmmmqmqqmnqrrd  should be accepted by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd']


negative traces---> 
['']



1  iteration complete



start formula depth: 1
learned LTL formula: q
Learning took:  0.5774922370910645  s
EQ test took  0.12578678131103516  s
new counterexample: q  should be rejected by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd']


negative traces---> 
['', 'q']



2  iteration complete



start formula depth: 1
learned LTL formula: (X q)
Learning took:  1.9067866802215576  s
EQ test took  0.43053650856018066  s
new counterexample: rmrqrard  should be accepted by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard']


negative traces---> 
['', 'q']



3  iteration complete



start formula depth: 2
learned LTL formula: (F r)
Learning took:  2.0040619373321533  s
EQ test took  0.13541102409362793  s
new counterexample: r  should be rejected by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard']


negative traces---> 
['', 'q', 'r']



4  iteration complete



start formula depth: 2
learned LTL formula: (F m)
Learning took:  2.074333429336548  s
No positive counterexample found
EQ test took  0.4523787498474121  s
new counterexample: m  should be rejected by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard']


negative traces---> 
['', 'q', 'r', 'm']



5  iteration complete



start formula depth: 2
learned LTL formula: (F d)
Learning took:  2.248692035675049  s
No positive counterexample found
EQ test took  0.3725094795227051  s
new counterexample: d  should be rejected by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard']


negative traces---> 
['', 'q', 'r', 'm', 'd']



6  iteration complete



start formula depth: 2
learned LTL formula: (F (X r))
Learning took:  10.005306720733643  s
No positive counterexample found
EQ test took  0.48949241638183594  s
new counterexample: pr  should be rejected by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard']


negative traces---> 
['', 'q', 'r', 'm', 'd', 'pr']



7  iteration complete



start formula depth: 3
learned LTL formula: (X (F m))
Learning took:  6.125933408737183  s
No positive counterexample found
EQ test took  0.5254864692687988  s
new counterexample: am  should be rejected by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard']


negative traces---> 
['', 'q', 'r', 'm', 'd', 'pr', 'am']



8  iteration complete



start formula depth: 3
learned LTL formula: (X (F d))
Learning took:  6.503302812576294  s
No positive counterexample found
EQ test took  0.6333768367767334  s
new counterexample: nd  should be rejected by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard']


negative traces---> 
['', 'q', 'r', 'm', 'd', 'pr', 'am', 'nd']



9  iteration complete



start formula depth: 3
learned LTL formula: (F (X q))
Learning took:  6.8277201652526855  s
EQ test took  0.6157982349395752  s
new counterexample: prnpmnaprrd  should be accepted by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard', 'prnpmnaprrd']


negative traces---> 
['', 'q', 'r', 'm', 'd', 'pr', 'am', 'nd']



10  iteration complete



start formula depth: 3
learned LTL formula: (X (F (X d)))
Learning took:  25.503907918930054  s
EQ test took  0.6888754367828369  s
new counterexample: mmd  should be rejected by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard', 'prnpmnaprrd']


negative traces---> 
['', 'q', 'r', 'm', 'd', 'pr', 'am', 'nd', 'mmd']



11  iteration complete



start formula depth: 4
learned LTL formula: (X (X (~ d)))
Learning took:  19.589104652404785  s
No positive counterexample found
EQ test took  0.5288584232330322  s
new counterexample: mqp  should be rejected by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard', 'prnpmnaprrd']


negative traces---> 
['', 'q', 'r', 'm', 'd', 'pr', 'am', 'nd', 'mmd', 'mqp']



12  iteration complete



start formula depth: 4
learned LTL formula: (X (X (F r)))
Learning took:  19.8250949382782  s
No positive counterexample found
EQ test took  0.7364597320556641  s
new counterexample: aqr  should be rejected by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard', 'prnpmnaprrd']


negative traces---> 
['', 'q', 'r', 'm', 'd', 'pr', 'am', 'nd', 'mmd', 'mqp', 'aqr']



13  iteration complete



start formula depth: 4
learned LTL formula: ((~ r) U (r & (r U (~ r))))
Learning took:  58.28991651535034  s
No positive counterexample found
EQ test took  0.8662421703338623  s
new counterexample: rp  should be rejected by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard', 'prnpmnaprrd']


negative traces---> 
['', 'q', 'r', 'm', 'd', 'pr', 'am', 'nd', 'mmd', 'mqp', 'aqr', 'rp']



14  iteration complete



start formula depth: 5
learned LTL formula: (X (X (X (m -> m))))
Learning took:  40.37177324295044  s
No positive counterexample found
EQ test took  0.4829113483428955  s
new counterexample: pdrp  should be rejected by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard', 'prnpmnaprrd']


negative traces---> 
['', 'q', 'r', 'm', 'd', 'pr', 'am', 'nd', 'mmd', 'mqp', 'aqr', 'rp', 'pdrp']



15  iteration complete



start formula depth: 5
learned LTL formula: ((F r) & (F m))
Learning took:  42.01728439331055  s
EQ test took  1.2649784088134766  s
new counterexample: qrnrprpnrarpqrd  should be accepted by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard', 'prnpmnaprrd', 'qrnrprpnrarpqrd']


negative traces---> 
['', 'q', 'r', 'm', 'd', 'pr', 'am', 'nd', 'mmd', 'mqp', 'aqr', 'rp', 'pdrp']



16  iteration complete



start formula depth: 5
learned LTL formula: (F (r & (X d)))
Learning took:  55.919256925582886  s
EQ test took  0.43071484565734863  s
new counterexample: rd  should be rejected by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard', 'prnpmnaprrd', 'qrnrprpnrarpqrd']


negative traces---> 
['', 'q', 'r', 'm', 'd', 'pr', 'am', 'nd', 'mmd', 'mqp', 'aqr', 'rp', 'pdrp', 'rd']



17  iteration complete



start formula depth: 5
learned LTL formula: (X (X (X (F d))))
Learning took:  55.352280616760254  s
No positive counterexample found
EQ test took  1.1188836097717285  s
new counterexample: aqmd  should be rejected by implementation


positive traces---> 
['qqmrnmmmqmqqmnqrrd', 'rmrqrard', 'prnpmnaprrd', 'qrnrprpnrarpqrd']


negative traces---> 
['', 'q', 'r', 'm', 'd', 'pr', 'am', 'nd', 'mmd', 'mqp', 'aqr', 'rp', 'pdrp', 'rd', 'aqmd']



18  iteration complete





epsilon= 0.05 delta= 0.05 max_trace_length= 20
query: (F(m|n))&((p|q|r)U(m|n))
final ltl:  (X (X (X (F d))))
incomplete formula

Time taken: 401.0755615234375
target                     query        explanation status  rnn score  explanation score  explanation score on ground truth  extraction time
email match  (F(m|n))&((p|q|r)U(m|n))  (X (X (X (F d))))  False      100.0                0.0                                0.0       401.075562
query: (F(m|n))&(F(a & X(m|n)))


positive traces---> 
[]


negative traces---> 
[]



learned LTL formula: true
Learning took:  0.3859992027282715  s
EQ test took  0.0009555816650390625  s
new counterexample:   should be rejected by implementation


positive traces---> 
[]


negative traces---> 
['']



0  iteration complete



learned LTL formula: false
Learning took:  0.38614583015441895  s
EQ test took  0.7944197654724121  s


epsilon= 0.05 delta= 0.05 max_trace_length= 20
query: (F(m|n))&(F(a & X(m|n)))
final ltl:  false

Time taken: 1.5731499195098877
target                     query explanation status  rnn score  explanation score  explanation score on ground truth  extraction time
email match  (F(m|n))&(F(a & X(m|n)))       false   True      100.0                0.0                                0.0          1.57315
Filename: /home/projects/11000744/bishwa/xRNN/PACTeacher/pac_teacher.py

Line #    Mem usage    Increment   Line Contents
================================================
   220 4008.422 MiB 2440.348 MiB       @profile
   221                                 def teach(self, learner, traces, timeout=20, verbose=True):
   222                                     # with timeout(time):
   223                             
   224 4008.422 MiB    0.000 MiB           start_time = time.time()
   225                             
   226 4008.434 MiB    0.000 MiB           for i in range(100):
   227                             
   228 4008.434 MiB    0.000 MiB               if(learner.current_formula_depth > self.max_formula_depth):
   229                                             if(verbose):
   230                                                 print("Max formula depth achieved")
   231                                             return learner, False
   232                                         """  
   233                                             For LTL learning, initialize  a process
   234                                             """
   235 4008.426 MiB    0.051 MiB               q = Queue()
   236 4008.426 MiB    0.000 MiB               p = Process(target=learner.learn_ltlf_and_dfa, args=(q,))
   237 4008.426 MiB    0.000 MiB               learning_start_time = time.time()
   238 4008.426 MiB    0.016 MiB               p.start()
   239 4008.426 MiB    0.004 MiB               p.join(timeout=max(0.5, timeout-(learning_start_time-start_time)))
   240 4008.426 MiB    0.000 MiB               p.terminate()
   241 4008.426 MiB    0.000 MiB               while p.exitcode == None:
   242 4006.719 MiB    0.000 MiB                   time.sleep(1)
   243 4008.426 MiB    0.000 MiB               if p.exitcode == 0:
   244                             
   245 4008.426 MiB    0.000 MiB                   if(verbose):
   246 4008.426 MiB    0.000 MiB                       equivalence_test_start_time = time.time()
   247 4008.426 MiB    0.000 MiB                       print("Learning took: ", equivalence_test_start_time -
   248 4008.426 MiB    0.000 MiB                             learning_start_time, " s")
   249 4008.434 MiB    0.066 MiB                   [learner] = q.get()
   250                             
   251                                             # learner.learn_ltlf_and_dfa()
   252 4008.434 MiB    0.000 MiB                   counterexample = self.equivalence_query_dfs(
   253 4035.555 MiB   65.730 MiB                       learner.dfa, verbose=verbose)
   254                             
   255 4035.555 MiB    0.000 MiB                   if(verbose):
   256 4035.555 MiB    0.000 MiB                       print("EQ test took ", time.time() -
   257 4035.555 MiB    0.004 MiB                             equivalence_test_start_time, " s")
   258 4035.555 MiB    0.000 MiB                   if counterexample is None:
   259 4035.555 MiB    0.000 MiB                       return learner,  True
   260                             
   261 4008.434 MiB    0.000 MiB                   if(self.query_dfa is None):
   262                                                 if(self.specification_dfa.classify_word(counterexample)):
   263                                                     if(verbose):
   264                             
   265                                                         print("new counterexample:", counterexample,
   266                                                               " should be accepted by implementation")
   267                                                     traces.add_positive_example(counterexample)
   268                                                 else:
   269                                                     if(verbose):
   270                             
   271                                                         print("new counterexample:", counterexample,
   272                                                               " should be rejected by implementation")
   273                                                     traces.add_negative_example(counterexample)
   274                                             else:
   275 4008.434 MiB    2.145 MiB                       if(self.specification_dfa.classify_word(counterexample) and self.query_dfa.classify_word(counterexample)):
   276 3924.594 MiB    0.000 MiB                           if(verbose):
   277                             
   278 3924.594 MiB    0.000 MiB                               print("new counterexample:", counterexample,
   279 3924.594 MiB    0.000 MiB                                     " should be accepted by implementation")
   280 3924.605 MiB    0.012 MiB                           traces.add_positive_example(counterexample)
   281                                                 else:
   282 4008.434 MiB    0.000 MiB                           if(verbose):
   283                             
   284 4008.434 MiB    0.000 MiB                               print("new counterexample:", counterexample,
   285 4008.434 MiB    0.000 MiB                                     " should be rejected by implementation")
   286 4008.434 MiB    2.000 MiB                           traces.add_negative_example(counterexample)
   287                                         else:
   288 4006.719 MiB    0.000 MiB                   return learner, False
   289                             
   290 4008.434 MiB    0.000 MiB               print(i, " iteration complete\n\n\n")
   291                             
   292                                     return learner, False


